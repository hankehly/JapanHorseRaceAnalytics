{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Create a binary classifier using the `features_20240217_v1` features dataset and deep learning. The dataset contains predicted and actual values with the same feature name. The prefix marks the source of the value. Use actual values for training and predicted values for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from hyperopt import STATUS_OK, SparkTrials, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll.base import scope\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, Schema\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from JapanHorseRaceAnalytics.utilities.base import get_base_dir, get_data_dir\n",
    "from JapanHorseRaceAnalytics.utilities.metrics import (\n",
    "    calculate_binary_classifier_statistics,\n",
    ")\n",
    "from JapanHorseRaceAnalytics.utilities.mlflow import get_colspecs\n",
    "from JapanHorseRaceAnalytics.utilities.structured_logger import logger\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/17 17:05:08 WARN Utils: Your hostname, Hanks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.40.105 instead (on interface en0)\n",
      "24/02/17 17:05:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/02/17 17:05:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "warehouse_dir = f\"{get_base_dir()}/spark-warehouse\"\n",
    "postgres_driver_path = f\"{get_base_dir()}/jars/postgresql-42.7.1.jar\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"20240211_competitors\")\n",
    "    .config(\"spark.driver.memory\", \"21g\")\n",
    "    .config(\"spark.driver.maxResultSize\", \"5g\")\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_dir)\n",
    "    .config(\"spark.jars\", postgres_driver_path)\n",
    "    .config(\"spark.executor.extraClassPath\", postgres_driver_path)\n",
    "    .config(\"spark.driver.extraClassPath\", postgres_driver_path)\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"event\": \"Read from parquet /Users/hankehly/Projects/JapanHorseRaceAnalytics/data/sql_tables/features_20240217_v1.snappy.parquet to pandas\", \"level\": \"info\", \"timestamp\": \"2024-02-17T08:39:33.184484Z\", \"logger\": \"__main__\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_馬番</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_本賞金</th>\n",
       "      <th>meta_単勝的中</th>\n",
       "      <th>meta_単勝払戻金</th>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <th>meta_複勝払戻金</th>\n",
       "      <th>meta_int_races_レースキー</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_場コード</th>\n",
       "      <th>cat_四半期</th>\n",
       "      <th>cat_距離</th>\n",
       "      <th>cat_事前_馬場状態コード</th>\n",
       "      <th>cat_事前_レース条件_トラック情報_右左</th>\n",
       "      <th>cat_事前_レース条件_トラック情報_内外</th>\n",
       "      <th>cat_事前_レース条件_種別</th>\n",
       "      <th>cat_事前_レース条件_条件</th>\n",
       "      <th>cat_事前_レース条件_記号</th>\n",
       "      <th>cat_事前_レース条件_重量</th>\n",
       "      <th>cat_事前_レース条件_グレード</th>\n",
       "      <th>num_事前_頭数</th>\n",
       "      <th>cat_実績_馬場状態コード</th>\n",
       "      <th>cat_実績_レース条件_トラック情報_右左</th>\n",
       "      <th>cat_実績_レース条件_トラック情報_内外</th>\n",
       "      <th>cat_実績_レース条件_種別</th>\n",
       "      <th>cat_実績_レース条件_条件</th>\n",
       "      <th>cat_実績_レース条件_記号</th>\n",
       "      <th>cat_実績_レース条件_重量</th>\n",
       "      <th>cat_実績_レース条件_グレード</th>\n",
       "      <th>num_実績_頭数</th>\n",
       "      <th>cat_トラック種別</th>\n",
       "      <th>num_事前_馬場差</th>\n",
       "      <th>num_実績_馬場差</th>\n",
       "      <th>cat_馬場状態内</th>\n",
       "      <th>cat_馬場状態中</th>\n",
       "      <th>cat_馬場状態外</th>\n",
       "      <th>num_直線馬場差最内</th>\n",
       "      <th>num_直線馬場差内</th>\n",
       "      <th>num_直線馬場差中</th>\n",
       "      <th>num_直線馬場差外</th>\n",
       "      <th>num_直線馬場差大外</th>\n",
       "      <th>cat_芝種類</th>\n",
       "      <th>cat_草丈</th>\n",
       "      <th>cat_転圧</th>\n",
       "      <th>cat_凍結防止剤</th>\n",
       "      <th>num_中間降水量</th>\n",
       "      <th>meta_int_race_horses_レースキー</th>\n",
       "      <th>meta_int_race_horses_馬番</th>\n",
       "      <th>num_事前_馬体重</th>\n",
       "      <th>...</th>\n",
       "      <th>num_競争相手平均調教師トップ3完走率差</th>\n",
       "      <th>num_競争相手平均調教師場所レース数差</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走差</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走差</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走率差</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走率差</th>\n",
       "      <th>num_競争相手平均調教師本賞金累計差</th>\n",
       "      <th>num_競争相手平均調教師1位完走平均賞金差</th>\n",
       "      <th>num_競争相手平均調教師レース数平均賞金差</th>\n",
       "      <th>meta_int_combinations_レースキー</th>\n",
       "      <th>meta_int_combinations_馬番</th>\n",
       "      <th>num_馬騎手レース数</th>\n",
       "      <th>num_馬騎手1位完走</th>\n",
       "      <th>num_馬騎手1位完走率</th>\n",
       "      <th>num_馬騎手トップ3完走</th>\n",
       "      <th>num_馬騎手トップ3完走率</th>\n",
       "      <th>num_馬騎手初二走</th>\n",
       "      <th>num_馬騎手同騎手</th>\n",
       "      <th>num_馬騎手場所レース数</th>\n",
       "      <th>num_馬騎手場所1位完走</th>\n",
       "      <th>num_馬騎手場所1位完走率</th>\n",
       "      <th>num_馬騎手場所トップ3完走</th>\n",
       "      <th>num_馬騎手場所トップ3完走率</th>\n",
       "      <th>num_馬調教師レース数</th>\n",
       "      <th>num_馬調教師1位完走</th>\n",
       "      <th>num_馬調教師1位完走率</th>\n",
       "      <th>num_馬調教師トップ3完走</th>\n",
       "      <th>num_馬調教師トップ3完走率</th>\n",
       "      <th>num_馬調教師初二走</th>\n",
       "      <th>num_馬調教師同調教師</th>\n",
       "      <th>num_馬調教師場所レース数</th>\n",
       "      <th>num_馬調教師場所1位完走</th>\n",
       "      <th>num_馬調教師場所1位完走率</th>\n",
       "      <th>num_馬調教師場所トップ3完走</th>\n",
       "      <th>num_馬調教師場所トップ3完走率</th>\n",
       "      <th>meta_int_race_weather_レースキー</th>\n",
       "      <th>num_temperature</th>\n",
       "      <th>num_precipitation</th>\n",
       "      <th>num_snowfall</th>\n",
       "      <th>num_snow_depth</th>\n",
       "      <th>num_wind_speed</th>\n",
       "      <th>cat_wind_direction</th>\n",
       "      <th>num_solar_radiation</th>\n",
       "      <th>num_local_air_pressure</th>\n",
       "      <th>num_sea_level_air_pressure</th>\n",
       "      <th>num_relative_humidity</th>\n",
       "      <th>num_vapor_pressure</th>\n",
       "      <th>num_dew_point_temperature</th>\n",
       "      <th>cat_weather</th>\n",
       "      <th>num_visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01011103</td>\n",
       "      <td>2001-08-04 01:45:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>芝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>476.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036119</td>\n",
       "      <td>-6.733333</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>0.125590</td>\n",
       "      <td>-18662.266667</td>\n",
       "      <td>-159.225818</td>\n",
       "      <td>-51.509013</td>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01011103</td>\n",
       "      <td>22.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>北西</td>\n",
       "      <td>2.9300</td>\n",
       "      <td>1010.950</td>\n",
       "      <td>1013.950</td>\n",
       "      <td>60.75</td>\n",
       "      <td>16.875</td>\n",
       "      <td>14.850</td>\n",
       "      <td>missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01011103</td>\n",
       "      <td>09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "      <td>01011103</td>\n",
       "      <td>2001-08-04 01:45:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>芝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011103</td>\n",
       "      <td>09</td>\n",
       "      <td>482.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068150</td>\n",
       "      <td>-9.933333</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.125590</td>\n",
       "      <td>-28766.800000</td>\n",
       "      <td>-206.365603</td>\n",
       "      <td>-72.468494</td>\n",
       "      <td>01011103</td>\n",
       "      <td>09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01011103</td>\n",
       "      <td>22.800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>北西</td>\n",
       "      <td>2.9300</td>\n",
       "      <td>1010.950</td>\n",
       "      <td>1013.950</td>\n",
       "      <td>60.75</td>\n",
       "      <td>16.875</td>\n",
       "      <td>14.850</td>\n",
       "      <td>missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01011204</td>\n",
       "      <td>14</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01011204</td>\n",
       "      <td>2001-08-05 02:15:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1800</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>14.0</td>\n",
       "      <td>芝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011204</td>\n",
       "      <td>14</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049687</td>\n",
       "      <td>15.769231</td>\n",
       "      <td>6.846154</td>\n",
       "      <td>9.923077</td>\n",
       "      <td>0.137634</td>\n",
       "      <td>0.149950</td>\n",
       "      <td>49377.500000</td>\n",
       "      <td>316.358601</td>\n",
       "      <td>86.088353</td>\n",
       "      <td>01011204</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01011204</td>\n",
       "      <td>22.300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.625</td>\n",
       "      <td>北北西</td>\n",
       "      <td>3.1400</td>\n",
       "      <td>1010.325</td>\n",
       "      <td>1013.325</td>\n",
       "      <td>64.00</td>\n",
       "      <td>17.225</td>\n",
       "      <td>15.150</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1090</td>\n",
       "      <td>01011303</td>\n",
       "      <td>2001-08-11 01:45:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1700</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>002</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>002</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>13.0</td>\n",
       "      <td>ダート</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>436.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.916667</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.115922</td>\n",
       "      <td>-1223.125000</td>\n",
       "      <td>-199.919166</td>\n",
       "      <td>12.856413</td>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01011303</td>\n",
       "      <td>23.475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.825</td>\n",
       "      <td>北</td>\n",
       "      <td>1.4350</td>\n",
       "      <td>1009.925</td>\n",
       "      <td>1012.925</td>\n",
       "      <td>65.00</td>\n",
       "      <td>18.725</td>\n",
       "      <td>16.475</td>\n",
       "      <td>missing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011304</td>\n",
       "      <td>07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>True</td>\n",
       "      <td>230</td>\n",
       "      <td>True</td>\n",
       "      <td>120</td>\n",
       "      <td>01011304</td>\n",
       "      <td>2001-08-11 02:15:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>A3</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>16.0</td>\n",
       "      <td>芝</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011304</td>\n",
       "      <td>07</td>\n",
       "      <td>502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176155</td>\n",
       "      <td>45.066667</td>\n",
       "      <td>15.533333</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>0.169848</td>\n",
       "      <td>0.277041</td>\n",
       "      <td>230843.133333</td>\n",
       "      <td>516.538555</td>\n",
       "      <td>305.098488</td>\n",
       "      <td>01011304</td>\n",
       "      <td>07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>01011304</td>\n",
       "      <td>24.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.300</td>\n",
       "      <td>北北西</td>\n",
       "      <td>1.7175</td>\n",
       "      <td>1009.850</td>\n",
       "      <td>1012.825</td>\n",
       "      <td>61.50</td>\n",
       "      <td>18.425</td>\n",
       "      <td>16.225</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_レースキー meta_馬番  meta_着順  meta_本賞金  meta_単勝的中  meta_単勝払戻金  meta_複勝的中  \\\n",
       "0   01011103      04      6.0       0.0      False           0      False   \n",
       "1   01011103      09      2.0     200.0      False           0       True   \n",
       "2   01011204      14      6.0       0.0      False           0      False   \n",
       "3   01011303      06      3.0     130.0      False           0       True   \n",
       "4   01011304      07      1.0     510.0       True         230       True   \n",
       "\n",
       "   meta_複勝払戻金 meta_int_races_レースキー           meta_発走日時 meta_場コード cat_四半期  \\\n",
       "0           0             01011103 2001-08-04 01:45:00        01       3   \n",
       "1         120             01011103 2001-08-04 01:45:00        01       3   \n",
       "2           0             01011204 2001-08-05 02:15:00        01       3   \n",
       "3        1090             01011303 2001-08-11 01:45:00        01       3   \n",
       "4         120             01011304 2001-08-11 02:15:00        01       3   \n",
       "\n",
       "  cat_距離 cat_事前_馬場状態コード cat_事前_レース条件_トラック情報_右左 cat_事前_レース条件_トラック情報_内外  \\\n",
       "0   1200             20                      1                      1   \n",
       "1   1200             20                      1                      1   \n",
       "2   1800             10                      1                      1   \n",
       "3   1700             10                      1                      1   \n",
       "4   2000             10                      1                      1   \n",
       "\n",
       "  cat_事前_レース条件_種別 cat_事前_レース条件_条件 cat_事前_レース条件_記号 cat_事前_レース条件_重量  \\\n",
       "0              12              A3             102               3   \n",
       "1              12              A3             102               3   \n",
       "2              12              A3             102               3   \n",
       "3              12              A3             002               3   \n",
       "4              12              A3             102               3   \n",
       "\n",
       "  cat_事前_レース条件_グレード  num_事前_頭数 cat_実績_馬場状態コード cat_実績_レース条件_トラック情報_右左  \\\n",
       "0           missing       16.0             21                      1   \n",
       "1           missing       16.0             21                      1   \n",
       "2           missing       14.0             11                      1   \n",
       "3           missing       13.0             11                      1   \n",
       "4           missing       16.0             11                      1   \n",
       "\n",
       "  cat_実績_レース条件_トラック情報_内外 cat_実績_レース条件_種別 cat_実績_レース条件_条件 cat_実績_レース条件_記号  \\\n",
       "0                      1              12              A3             102   \n",
       "1                      1              12              A3             102   \n",
       "2                      1              12              A3             102   \n",
       "3                      1              12              A3             002   \n",
       "4                      1              12              A3             102   \n",
       "\n",
       "  cat_実績_レース条件_重量 cat_実績_レース条件_グレード  num_実績_頭数 cat_トラック種別  num_事前_馬場差  \\\n",
       "0               3           missing       16.0          芝         NaN   \n",
       "1               3           missing       16.0          芝         NaN   \n",
       "2               3           missing       14.0          芝         NaN   \n",
       "3               3           missing       13.0        ダート         NaN   \n",
       "4               3           missing       16.0          芝         NaN   \n",
       "\n",
       "   num_実績_馬場差 cat_馬場状態内 cat_馬場状態中 cat_馬場状態外  num_直線馬場差最内  num_直線馬場差内  \\\n",
       "0       -18.0         1         1         1          1.0         1.0   \n",
       "1       -18.0         1         1         1          1.0         1.0   \n",
       "2       -14.0         1         1         1          1.0         1.0   \n",
       "3       -19.0         1         1         1          1.0         1.0   \n",
       "4       -17.0         1         1         1          1.0         1.0   \n",
       "\n",
       "   num_直線馬場差中  num_直線馬場差外  num_直線馬場差大外  cat_芝種類   cat_草丈 cat_転圧 cat_凍結防止剤  \\\n",
       "0         0.0         0.0          0.0  missing  missing  False     False   \n",
       "1         0.0         0.0          0.0  missing  missing  False     False   \n",
       "2         0.0         0.0          0.0  missing  missing  False     False   \n",
       "3         0.0         0.0          0.0  missing  missing  False     False   \n",
       "4         0.0         0.0          0.0  missing  missing  False     False   \n",
       "\n",
       "   num_中間降水量 meta_int_race_horses_レースキー meta_int_race_horses_馬番  num_事前_馬体重  \\\n",
       "0        NaN                   01011103                      04       476.0   \n",
       "1        NaN                   01011103                      09       482.0   \n",
       "2        NaN                   01011204                      14       470.0   \n",
       "3        NaN                   01011303                      06       436.0   \n",
       "4        NaN                   01011304                      07       502.0   \n",
       "\n",
       "   ...  num_競争相手平均調教師トップ3完走率差  num_競争相手平均調教師場所レース数差 num_競争相手平均調教師場所1位完走差  \\\n",
       "0  ...              -0.036119             -6.733333            -1.066667   \n",
       "1  ...              -0.068150             -9.933333            -1.066667   \n",
       "2  ...               0.049687             15.769231             6.846154   \n",
       "3  ...               0.063804              7.750000             1.333333   \n",
       "4  ...               0.176155             45.066667            15.533333   \n",
       "\n",
       "   num_競争相手平均調教師場所トップ3完走差  num_競争相手平均調教師場所1位完走率差  num_競争相手平均調教師場所トップ3完走率差  \\\n",
       "0               -0.733333              -0.010847                 0.125590   \n",
       "1               -1.800000               0.018783                 0.125590   \n",
       "2                9.923077               0.137634                 0.149950   \n",
       "3                7.916667               0.039064                 0.115922   \n",
       "4               30.333333               0.169848                 0.277041   \n",
       "\n",
       "  num_競争相手平均調教師本賞金累計差 num_競争相手平均調教師1位完走平均賞金差 num_競争相手平均調教師レース数平均賞金差  \\\n",
       "0       -18662.266667            -159.225818             -51.509013   \n",
       "1       -28766.800000            -206.365603             -72.468494   \n",
       "2        49377.500000             316.358601              86.088353   \n",
       "3        -1223.125000            -199.919166              12.856413   \n",
       "4       230843.133333             516.538555             305.098488   \n",
       "\n",
       "  meta_int_combinations_レースキー  meta_int_combinations_馬番  num_馬騎手レース数  \\\n",
       "0                    01011103                        04          2.0   \n",
       "1                    01011103                        09          3.0   \n",
       "2                    01011204                        14          4.0   \n",
       "3                    01011303                        06          1.0   \n",
       "4                    01011304                        07          1.0   \n",
       "\n",
       "   num_馬騎手1位完走  num_馬騎手1位完走率  num_馬騎手トップ3完走  num_馬騎手トップ3完走率 num_馬騎手初二走  \\\n",
       "0          0.0           0.0            0.0        0.000000        0.0   \n",
       "1          0.0           0.0            2.0        0.666667        0.0   \n",
       "2          0.0           0.0            0.0        0.000000        0.0   \n",
       "3          0.0           0.0            0.0        0.000000        1.0   \n",
       "4          0.0           0.0            1.0        1.000000        1.0   \n",
       "\n",
       "   num_馬騎手同騎手  num_馬騎手場所レース数  num_馬騎手場所1位完走 num_馬騎手場所1位完走率 num_馬騎手場所トップ3完走  \\\n",
       "0         0.0            0.0            0.0            0.0             0.0   \n",
       "1         1.0            0.0            0.0            0.0             0.0   \n",
       "2         0.0            0.0            0.0            0.0             0.0   \n",
       "3         1.0            1.0            0.0            0.0             0.0   \n",
       "4         1.0            0.0            0.0            0.0             0.0   \n",
       "\n",
       "  num_馬騎手場所トップ3完走率 num_馬調教師レース数  num_馬調教師1位完走  num_馬調教師1位完走率  num_馬調教師トップ3完走  \\\n",
       "0              0.0          9.0           0.0            0.0             1.0   \n",
       "1              0.0          8.0           0.0            0.0             3.0   \n",
       "2              0.0         10.0           0.0            0.0             1.0   \n",
       "3              0.0          5.0           0.0            0.0             0.0   \n",
       "4              0.0          1.0           0.0            0.0             1.0   \n",
       "\n",
       "  num_馬調教師トップ3完走率 num_馬調教師初二走 num_馬調教師同調教師  num_馬調教師場所レース数  num_馬調教師場所1位完走  \\\n",
       "0        0.111111         0.0          1.0             0.0             0.0   \n",
       "1        0.375000         0.0          1.0             0.0             0.0   \n",
       "2        0.100000         0.0          1.0             0.0             0.0   \n",
       "3        0.000000         0.0          1.0             1.0             0.0   \n",
       "4        1.000000         1.0          1.0             0.0             0.0   \n",
       "\n",
       "   num_馬調教師場所1位完走率  num_馬調教師場所トップ3完走  num_馬調教師場所トップ3完走率  \\\n",
       "0              0.0               0.0                0.0   \n",
       "1              0.0               0.0                0.0   \n",
       "2              0.0               0.0                0.0   \n",
       "3              0.0               0.0                0.0   \n",
       "4              0.0               0.0                0.0   \n",
       "\n",
       "   meta_int_race_weather_レースキー  num_temperature  num_precipitation  \\\n",
       "0                     01011103           22.800                0.0   \n",
       "1                     01011103           22.800                0.0   \n",
       "2                     01011204           22.300                0.0   \n",
       "3                     01011303           23.475                0.0   \n",
       "4                     01011304           24.125                0.0   \n",
       "\n",
       "   num_snowfall  num_snow_depth  num_wind_speed  cat_wind_direction  \\\n",
       "0           NaN             0.0           3.900                  北西   \n",
       "1           NaN             0.0           3.900                  北西   \n",
       "2           NaN             0.0           4.625                 北北西   \n",
       "3           NaN             0.0           0.825                   北   \n",
       "4           NaN             0.0           1.300                 北北西   \n",
       "\n",
       "   num_solar_radiation  num_local_air_pressure num_sea_level_air_pressure  \\\n",
       "0               2.9300                1010.950                   1013.950   \n",
       "1               2.9300                1010.950                   1013.950   \n",
       "2               3.1400                1010.325                   1013.325   \n",
       "3               1.4350                1009.925                   1012.925   \n",
       "4               1.7175                1009.850                   1012.825   \n",
       "\n",
       "  num_relative_humidity num_vapor_pressure num_dew_point_temperature  \\\n",
       "0                 60.75             16.875                    14.850   \n",
       "1                 60.75             16.875                    14.850   \n",
       "2                 64.00             17.225                    15.150   \n",
       "3                 65.00             18.725                    16.475   \n",
       "4                 61.50             18.425                    16.225   \n",
       "\n",
       "  cat_weather num_visibility  \n",
       "0     missing            NaN  \n",
       "1     missing            NaN  \n",
       "2           1           30.0  \n",
       "3     missing            NaN  \n",
       "4           2           30.0  \n",
       "\n",
       "[5 rows x 886 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_hive_table(\n",
    "    table_name: str,\n",
    "    schema: str,\n",
    "    spark_session: SparkSession,\n",
    "    use_cache: bool = True,\n",
    "):\n",
    "    save_path = get_data_dir() / \"sql_tables\" / f\"{table_name}.snappy.parquet\"\n",
    "    if use_cache and save_path.exists():\n",
    "        logger.info(f\"Read from parquet {save_path} to pandas\")\n",
    "        return pd.read_parquet(save_path)\n",
    "    logger.info(f\"Read from hive {schema}.{table_name}\")\n",
    "    spark_df = spark_session.read.table(f\"{schema}.{table_name}\")\n",
    "    logger.info(f\"Write to parquet {save_path}\")\n",
    "    spark_df.write.mode(\"overwrite\").parquet(str(save_path))\n",
    "    logger.info(f\"Read from parquet {save_path} to pandas\")\n",
    "    return pd.read_parquet(save_path)\n",
    "\n",
    "\n",
    "data = read_hive_table(\n",
    "    table_name=\"features_20240217_v1\",\n",
    "    schema=\"jhra_curated\",\n",
    "    spark_session=spark,\n",
    "    # use_cache=False,\n",
    ")\n",
    "\n",
    "# For all columns beginning with cat_, cast to string and fillna with \"missing\"\n",
    "data = data.astype(\n",
    "    {col: \"string\" for col in data.columns if re.match(r\"^cat_\", col) and col}\n",
    ")\n",
    "data = data.fillna({col: \"missing\" for col in data.columns if re.match(r\"^cat_\", col) and col})\n",
    "\n",
    "# Set the dtype of all columns beginning with cat_ to category\n",
    "data = data.astype(\n",
    "    {col: \"category\" for col in data.columns if re.match(r\"^cat_\", col) and col}\n",
    ")\n",
    "# Set the dtype of all columns beginning with num_ to float64\n",
    "data = data.astype(\n",
    "    {col: \"float64\" for col in data.columns if re.match(r\"^num_\", col) and col}\n",
    ")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Split Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (886532, 886)\n",
      "X_test: (221634, 886)\n",
      "y_train: (886532,)\n",
      "y_test: (221634,)\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "y = data[\"meta_複勝的中\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective_fn(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    df_payout: pd.DataFrame,\n",
    "    experiment_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    df_payout should have the same index as *_test and have the following columns:\n",
    "    * レースキー\n",
    "    * 馬番\n",
    "    * 距離\n",
    "    * 発走日時\n",
    "    * 年齢\n",
    "    * グレード\n",
    "    * 場コード\n",
    "    * payout - amount won if betting 100 yen.\n",
    "    \"\"\"\n",
    "\n",
    "    def train(params):\n",
    "        def profit_loss(row, payout_column_name, bet_amount=100):\n",
    "            if row[\"pred\"] and row[\"actual\"]:\n",
    "                payout = row[payout_column_name] * (bet_amount / 100)\n",
    "                return payout - bet_amount\n",
    "            elif row[\"pred\"] and not row[\"actual\"]:\n",
    "                return -bet_amount\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        mlflow.set_experiment(experiment_name=experiment_name)\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            numeric_features = X_train.select_dtypes(\"number\").columns.tolist()\n",
    "            categorical_features = X_train.select_dtypes(\"category\").columns.tolist()\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    (\"num\", StandardScaler(), numeric_features),\n",
    "                    (\n",
    "                        \"cat\",\n",
    "                        OneHotEncoder(handle_unknown=\"ignore\"),\n",
    "                        categorical_features,\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            model = Pipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"classifier\", lgb.LGBMClassifier(**params)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # RestException: INVALID_PARAMETER_VALUE: Dataset schema exceeds the maximum length of 65535\n",
    "            # Xy_train = pd.concat((X_train, y_train), axis=1)\n",
    "            # dataset = mlflow.data.from_pandas(Xy_train, targets=y_train.name)\n",
    "            # mlflow.log_input(dataset, context=\"train\")\n",
    "\n",
    "            input_schema = Schema(get_colspecs(X_train))\n",
    "            output_schema = Schema([ColSpec(\"double\", y_train.name)])\n",
    "            signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "            input_example = X_train.iloc[:25]\n",
    "            model.fit(X_train, y_train)\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                signature=signature,\n",
    "                input_example=input_example,\n",
    "                artifact_path=\"model\",\n",
    "            )\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            metrics = {\n",
    "                \"loss\": log_loss(y_test, y_pred_proba),\n",
    "                \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"precision\": precision_score(y_test, y_pred),\n",
    "                \"recall\": recall_score(y_test, y_pred),\n",
    "                \"f1\": f1_score(y_test, y_pred),\n",
    "                \"roc_auc\": roc_auc_score(y_test, y_pred),\n",
    "            }\n",
    "            mlflow.log_metrics(metrics)\n",
    "\n",
    "            # Calculate payout rates by group\n",
    "            results = pd.concat(\n",
    "                [\n",
    "                    df_payout,\n",
    "                    pd.DataFrame(\n",
    "                        np.c_[y_test, y_pred, y_pred_proba],\n",
    "                        columns=[\"actual\", \"pred\", \"pred_proba_true\"],\n",
    "                    ),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "            payout_all = calculate_binary_classifier_statistics(\n",
    "                results, group_by=None, payout_column_name=\"payout\"\n",
    "            )\n",
    "            payout_month = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=results[\"発走日時\"].dt.month,\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_distance = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=pd.cut(results[\"距離\"], bins=[0, 1400, 1800, 10000]),\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_season = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=results[\"発走日時\"].dt.month % 12 // 3,\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_year = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=results[\"発走日時\"].dt.year,\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_age = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=pd.cut(results[\"年齢\"], bins=[0, 3, 6, 100]),\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_grade = calculate_binary_classifier_statistics(\n",
    "                results,\n",
    "                group_by=results[\"グレード\"],\n",
    "                payout_column_name=\"payout\",\n",
    "            )\n",
    "            payout_racetrack = calculate_binary_classifier_statistics(\n",
    "                results, group_by=results[\"場コード\"], payout_column_name=\"payout\"\n",
    "            )\n",
    "            payout = (\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        pd.DataFrame(payout_all).T.assign(group=\"all\"),\n",
    "                        pd.DataFrame(payout_month).T.assign(group=\"month\"),\n",
    "                        pd.DataFrame(payout_distance).T.assign(group=\"distance\"),\n",
    "                        pd.DataFrame(payout_season).T.assign(group=\"season\"),\n",
    "                        pd.DataFrame(payout_year).T.assign(group=\"year\"),\n",
    "                        pd.DataFrame(payout_age).T.assign(group=\"horse_age\"),\n",
    "                        pd.DataFrame(payout_grade).T.assign(group=\"grade\"),\n",
    "                        pd.DataFrame(payout_racetrack).T.assign(group=\"racetrack\"),\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "                .rename_axis(index=\"part\")\n",
    "                .reset_index()\n",
    "            )\n",
    "            # Move \"group\" and \"part\" columns to the first position in this dataframe\n",
    "            payout = payout[\n",
    "                [\"group\", \"part\"]\n",
    "                + [c for c in payout.columns if c not in [\"group\", \"part\"]]\n",
    "            ]\n",
    "\n",
    "            # Save payout rates as csv\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"payout_rate_\", suffix=\".csv\") as f:\n",
    "                payout.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Log payout rates as metrics\n",
    "            payout_metrics = {}\n",
    "            for group_name, group in payout.groupby(\"group\"):\n",
    "                for i, row in group.iterrows():\n",
    "                    key = re.sub(r\"\\W\", \"_\", f\"payout_rate_{group_name}_{row['part']}\")\n",
    "                    payout_metrics[key] = row[\"payout_rate\"]\n",
    "            mlflow.log_metrics(payout_metrics)\n",
    "\n",
    "            # Suppress UserWarning messages from matplotlib\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "            # Plot payout rates by group\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "            for (group, df), ax in zip(payout.groupby(\"group\"), axes.flatten()):\n",
    "                sns.barplot(x=\"part\", y=\"payout_rate\", data=df, ax=ax)\n",
    "                ax.set_title(group)\n",
    "                ax.set_ylim(0, 150)\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "                ax.set_ylabel(\"payout rate\")\n",
    "                ax.set_xlabel(\"\")\n",
    "                ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"payout_rate_\", suffix=\".png\") as f:\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Plot bank balance over time\n",
    "            results[\"profit_loss\"] = results.apply(\n",
    "                profit_loss, args=(\"payout\", 100), axis=1\n",
    "            )\n",
    "            daily_profit_loss = results.groupby(\"発走日時\")[\"profit_loss\"].sum()\n",
    "            bank_balance = daily_profit_loss.cumsum()\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            ax = plt.subplot(1, 1, 1)\n",
    "            ax.plot(bank_balance.index, bank_balance.values)\n",
    "            ax.set_title(\"Bank Balance\")\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Bank Balance\")\n",
    "            ax.grid(True)\n",
    "            ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{x:,.0f}\"))\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"bank_balance_\", suffix=\".png\"\n",
    "            ) as f:\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Confusion Matrix\n",
    "            conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "            _, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt=\"g\", cmap=\"Blues\", ax=ax1)\n",
    "            ax1.set_xlabel(\"Predicted\")\n",
    "            ax1.set_ylabel(\"Actual\")\n",
    "            ax1.set_title(\"Confusion Matrix\")\n",
    "            sns.heatmap(\n",
    "                conf_matrix / conf_matrix.sum(axis=1)[:, None],\n",
    "                annot=True,\n",
    "                fmt=\".2%\",\n",
    "                cmap=\"Blues\",\n",
    "                ax=ax2,\n",
    "            )\n",
    "            ax2.set_xlabel(\"Predicted\")\n",
    "            ax2.set_ylabel(\"Actual\")\n",
    "            ax2.set_title(\"Normalized Confusion Matrix\")\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"confusion_matrix_\", suffix=\".png\"\n",
    "            ) as f:\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # ROC Curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            _, ax = plt.subplots(figsize=(10, 10))\n",
    "            ax.plot(\n",
    "                fpr,\n",
    "                tpr,\n",
    "                color=\"darkorange\",\n",
    "                lw=2,\n",
    "                label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
    "            )\n",
    "            ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "            ax.set_xlim([0.0, 1.0])\n",
    "            ax.set_ylim([0.0, 1.0])\n",
    "            ax.set_xlabel(\"False Positive Rate\")\n",
    "            ax.set_ylabel(\"True Positive Rate\")\n",
    "            ax.set_title(\"Receiver Operating Characteristic\")\n",
    "            ax.legend(loc=\"lower right\")\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"roc_curve_\", suffix=\".png\") as f:\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Feature Importances\n",
    "            feature_importances = zip(\n",
    "                model.named_steps[\"preprocessor\"].get_feature_names_out(),\n",
    "                model.named_steps[\"classifier\"].feature_importances_,\n",
    "            )\n",
    "            feature_importances_df = (\n",
    "                pd.DataFrame(\n",
    "                    data=feature_importances, columns=[\"feature\", \"importance\"]\n",
    "                )\n",
    "                .sort_values(\"importance\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"feature_importance_\", suffix=\".csv\"\n",
    "            ) as f:\n",
    "                feature_importances_df.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            font_properties = fm.FontProperties(\n",
    "                fname=\"/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc\"\n",
    "            )\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "            plt.figure(figsize=(10, 12))\n",
    "            ax = sns.barplot(\n",
    "                x=\"importance\", y=\"feature\", data=feature_importances_df.iloc[:50]\n",
    "            )\n",
    "            ax.set_title(\"Feature Importances (Top 50)\", fontproperties=font_properties)\n",
    "            ax.set_xlabel(\"Importance\", fontproperties=font_properties)\n",
    "            ax.set_ylabel(\"Features\", fontproperties=font_properties)\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontproperties(font_properties)\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"feature_importance_\", suffix=\".png\"\n",
    "            ) as f:\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            return {\"status\": STATUS_OK, \"params\": params, \"model\": model, **metrics}\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"boosting_type\": hp.choice(\"boosting_type\", [\"gbdt\", \"dart\", \"goss\"]),\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", -5, 0),  # between e^-5 and 1\n",
    "    \"n_estimators\": scope.int(hp.quniform(\"n_estimators\", 100, 1000, 1)),\n",
    "    \"max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 10, 1)),\n",
    "    \"num_leaves\": scope.int(hp.quniform(\"num_leaves\", 20, 150, 1)),\n",
    "    \"min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 20, 500, 1)),\n",
    "    \"feature_fraction\": hp.uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "    \"lambda_l1\": hp.uniform(\"lambda_l1\", 0, 5),\n",
    "    \"lambda_l2\": hp.uniform(\"lambda_l2\", 0, 5),\n",
    "    \"min_split_gain\": hp.uniform(\"min_split_gain\", 0, 1),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.001, 10),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 1.0),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0.0, 1.0),\n",
    "    \"objective\": \"binary\",\n",
    "    \"class_weight\": \"balanced\",\n",
    "    \"verbose\": -1,\n",
    "    \"seed\": 80,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data.columns.tolist()\n",
    "\n",
    "# Get all the features names for the actual data\n",
    "names_actual = []\n",
    "for name in names:\n",
    "    if \"_事前_\" in name:\n",
    "        continue\n",
    "    elif name.startswith(\"meta_\"):\n",
    "        continue\n",
    "    elif name == \"cat_トラック種別\":\n",
    "        continue\n",
    "    else:\n",
    "        names_actual.append(name)\n",
    "\n",
    "names_actual_prep = [\n",
    "    name.replace(\"_実績\", \"\") if \"_実績\" in name else name for name in names_actual\n",
    "]\n",
    "\n",
    "\n",
    "names_before = []\n",
    "for name in names:\n",
    "    if \"_実績_\" in name:\n",
    "        continue\n",
    "    elif name.startswith(\"meta_\"):\n",
    "        continue\n",
    "    elif name == \"cat_トラック種別\":\n",
    "        continue\n",
    "    else:\n",
    "        names_before.append(name)\n",
    "\n",
    "names_before_prep = [\n",
    "    name.replace(\"_事前\", \"\") if \"_事前\" in name else name for name in names_before\n",
    "]\n",
    "\n",
    "# Check if the names are the same\n",
    "assert sorted(names_actual_prep) == sorted(names_before_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turf Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_turf = X_train[\"cat_トラック種別\"] == \"芝\"\n",
    "mask_test_turf = X_test[\"cat_トラック種別\"] == \"芝\"\n",
    "\n",
    "X_train_turf = X_train[mask_train_turf][names_actual]\n",
    "X_train_turf.columns = names_actual_prep\n",
    "y_train_turf = y_train[mask_train_turf]\n",
    "\n",
    "X_test_turf = X_test[mask_test_turf][names_before]\n",
    "X_test_turf.columns = names_before_prep\n",
    "y_test_turf = y_test[mask_test_turf]\n",
    "\n",
    "assert set(X_train_turf.columns) == set(X_test_turf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "Collecting scikeras\n",
      "  Downloading scikeras-0.12.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: packaging>=0.21 in ./.venv/lib/python3.11/site-packages (from scikeras) (23.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in ./.venv/lib/python3.11/site-packages (from scikeras) (1.3.2)\n",
      "Requirement already satisfied: tensorflow-metal<2.0.0,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from scikeras) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
      "Requirement already satisfied: wheel~=0.35 in ./.venv/lib/python3.11/site-packages (from tensorflow-metal<2.0.0,>=1.1.0->scikeras) (0.42.0)\n",
      "Requirement already satisfied: six>=1.15.0 in ./.venv/lib/python3.11/site-packages (from tensorflow-metal<2.0.0,>=1.1.0->scikeras) (1.16.0)\n",
      "Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_features = X_train_turf.select_dtypes(\"number\").columns.tolist()\n",
    "categorical_features = X_train_turf.select_dtypes(\"category\").columns.tolist()\n",
    "\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer()),  # First, impute missing values\n",
    "        (\"scaler\", StandardScaler()),  # Then, scale the data\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\"),\n",
    "            categorical_features,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_shape = preprocessor.fit_transform(X_train_turf).shape[1]\n",
    "\n",
    "\n",
    "# def build_fn(input_shape):\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(500, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(250, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model = KerasClassifier(\n",
    "    model=model,\n",
    "    # input_shape=input_shape,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-17 17:51:30.491731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10627/10627 [==============================] - 124s 11ms/step - loss: 15.1681 - accuracy: 0.8662 - val_loss: 27.0616 - val_accuracy: 0.9043\n",
      "Epoch 2/100\n",
      "10627/10627 [==============================] - 122s 11ms/step - loss: 166.5807 - accuracy: 0.8861 - val_loss: 147.2011 - val_accuracy: 0.9059\n",
      "Epoch 3/100\n",
      "10627/10627 [==============================] - 160s 15ms/step - loss: 488.1297 - accuracy: 0.8963 - val_loss: 468.1721 - val_accuracy: 0.9039\n",
      "Epoch 4/100\n",
      " 2198/10627 [=====>........................] - ETA: 2:30 - loss: 705.3856 - accuracy: 0.9008"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train_turf, y_train_turf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_turf, y_test_turf)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_payout_renamed_columns = {\n",
    "    \"meta_レースキー\": \"レースキー\",\n",
    "    \"meta_馬番\": \"馬番\",\n",
    "    \"cat_距離\": \"距離\",\n",
    "    \"meta_発走日時\": \"発走日時\",\n",
    "    \"meta_複勝払戻金\": \"payout\",\n",
    "    \"num_年齢\": \"年齢\",\n",
    "    \"cat_実績_レース条件_グレード\": \"グレード\",\n",
    "    \"meta_場コード\": \"場コード\",\n",
    "}\n",
    "\n",
    "df_payout_turf = (\n",
    "    data.iloc[X_test_turf.index]\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns=df_payout_renamed_columns)[df_payout_renamed_columns.values()]\n",
    ")\n",
    "\n",
    "experiment_name_turf = \"20240217_before_after__turf\"\n",
    "if mlflow.get_experiment_by_name(experiment_name_turf) is None:\n",
    "    mlflow.create_experiment(experiment_name_turf)\n",
    "\n",
    "fn_turf = create_objective_fn(\n",
    "    X_train_turf,\n",
    "    y_train_turf,\n",
    "    X_test_turf,\n",
    "    y_test_turf,\n",
    "    df_payout=df_payout_turf,\n",
    "    experiment_name=experiment_name_turf,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001952 seconds\n",
      "TPE using 0 trials\n",
      "build_posterior_wrapper took 0.002027 seconds\n",
      "TPE using 1/1 trials with best loss inf\n",
      "build_posterior_wrapper took 0.002119 seconds\n",
      "TPE using 2/2 trials with best loss inf\n",
      "build_posterior_wrapper took 0.002132 seconds\n",
      "TPE using 3/3 trials with best loss inf\n",
      "2024/02/17 16:12:32 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/1d4887e15e294e748232366941977d29/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/60 [02:45<2:42:19, 165.08s/trial, best loss: 0.9462831393144859]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.006418 seconds\n",
      "TPE using 4/4 trials with best loss 0.946283\n",
      "2024/02/17 16:12:47 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/63f317f9aef94e17ad37f9a60024585c/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/60 [02:59<1:13:52, 76.43s/trial, best loss: 0.9239293371013857] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.002626 seconds                       (0 + 1) / 1]\n",
      "TPE using 5/5 trials with best loss 0.923929\n",
      "2024/02/17 16:13:04 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/d2ae830d32474d38a2e769cb5dd660f9/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [03:19<48:14, 50.77s/trial, best loss: 0.7720435299667909]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.014627 secondse 5:>                  (0 + 1) / 1]\n",
      "TPE using 6/6 trials with best loss 0.772044\n",
      "2024/02/17 16:15:20 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/605f9cb336d94979b659057625f13016/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 4/60 [05:35<1:18:35, 84.21s/trial, best loss: 0.7720435299667909]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.003944 secondse 6:>                  (0 + 1) / 1]\n",
      "TPE using 7/7 trials with best loss 0.772044\n",
      "2024/02/17 16:16:34 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/a151165073f44e68af32532b1f30401b/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 5/60 [06:47<1:13:22, 80.05s/trial, best loss: 0.7330719958835319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.004351 secondse 7:>                  (0 + 1) / 1]\n",
      "TPE using 8/8 trials with best loss 0.733072\n",
      "2024/02/17 16:17:29 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/13edd6a323ae47b7b68af95c4090620f/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 6/60 [07:42<1:04:12, 71.34s/trial, best loss: 0.7330719958835319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.004967 secondse 8:>                  (0 + 1) / 1]\n",
      "TPE using 9/9 trials with best loss 0.733072\n",
      "2024/02/17 16:20:36 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/8c3d6e8b710f458db373b0ae2b163f9d/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 7/60 [10:51<1:36:56, 109.75s/trial, best loss: 0.7330719958835319]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.002827 seconds\n",
      "TPE using 10/10 trials with best loss 0.733072\n",
      "2024/02/17 16:21:36 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/054d6f4a2d644f16a6b1d9a37f84d82e/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/02/17 16:21:38 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/5139b284621c43fd9596d898f1ff380c/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 8/60 [11:48<1:20:42, 93.13s/trial, best loss: 0.6437892481832604] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.030781 secondse 10:>                 (0 + 1) / 1]\n",
      "TPE using 11/11 trials with best loss 0.643789\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 9/60 [11:50<54:57, 64.66s/trial, best loss: 0.6437892481832604]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.006282 seconds\n",
      "TPE using 12/12 trials with best loss 0.643789\n",
      "2024/02/17 16:22:05 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/c8b167e08c5d4f5b84d6775baf2c101d/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10/60 [12:30<47:24, 56.88s/trial, best loss: 0.6437892481832604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.017812 seconds\n",
      "TPE using 13/13 trials with best loss 0.643789\n",
      "24/02/17 16:23:16 WARN HikariPool: HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=45s439ms).\n",
      "24/02/17 16:23:16 WARN HikariPool: HikariPool-2 - Thread starvation or clock leap detected (housekeeper delta=45s436ms).\n",
      "2024/02/17 16:25:27 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/2b1e7631803f4e5d8d929d194379b614/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/02/17 16:25:29 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/06a5ce96aefb4a26928a41c1065ac79f/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 11/60 [15:39<1:19:29, 97.34s/trial, best loss: 0.6437892481832604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.017210 seconds\n",
      "Closing down clientserver connection\n",
      "TPE using 14/14 trials with best loss 0.643789\n",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 12/60 [15:40<54:32, 68.19s/trial, best loss: 0.6437892481832604]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.003382 seconds\n",
      "TPE using 15/15 trials with best loss 0.643789\n",
      "2024/02/17 16:25:45 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/5e0c78ae06164bd0a35271902da05ef2/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 13/60 [15:56<40:57, 52.29s/trial, best loss: 0.6437892481832604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.006494 seconds\n",
      "TPE using 16/16 trials with best loss 0.643789\n",
      "2024/02/17 16:28:09 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/e251dd595a9d4ced8f7c8e5c88f02ebf/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "2024/02/17 16:28:14 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/fdffba24cc094ceabbc66eb4c40fae92/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 14:>                 (0 + 1) / 1][Stage 16:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 14/60 [18:21<1:01:28, 80.18s/trial, best loss: 0.6437892481832604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.004367 seconds\n",
      "TPE using 17/17 trials with best loss 0.643789\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 15/60 [18:24<42:45, 57.00s/trial, best loss: 0.5279504399227686]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.005603 seconds                       (0 + 1) / 1]\n",
      "TPE using 18/18 trials with best loss 0.527950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800.681s][warning][gc,alloc] dispatcher-BlockManagerMaster: Retried waiting for GCLocker too often allocating 256 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/17 16:29:40 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/4dac1a4a1bcc4d6e93e19b8f80c46825/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 16/60 [19:55<49:21, 67.30s/trial, best loss: 0.5279504399227686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.010563 seconds\n",
      "TPE using 19/19 trials with best loss 0.527950 18:>                 (0 + 1) / 1]\n",
      "2024/02/17 16:32:29 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/d4c34b1bfa2c41f2a63f0467285323f7/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 17/60 [22:43<1:09:58, 97.64s/trial, best loss: 0.5279504399227686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.016223 secondse 19:>                 (0 + 1) / 1]\n",
      "TPE using 20/20 trials with best loss 0.527950\n",
      "2024/02/17 16:36:43 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/0f7fad8267044321a34af5d75744a5f1/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 19:>                 (0 + 1) / 1][Stage 20:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 18/60 [26:57<1:41:09, 144.51s/trial, best loss: 0.5279504399227686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.032197 seconds\n",
      "TPE using 21/21 trials with best loss 0.527950\n",
      "2024/02/17 16:37:22 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/d7f83f3c865147a69e8ca6c9c33b9f0b/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 19/60 [27:39<1:17:38, 113.62s/trial, best loss: 0.5279504399227686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.155659 seconds                       (0 + 1) / 1]\n",
      "TPE using 22/22 trials with best loss 0.527950 21:>                 (0 + 1) / 1]\n",
      "2024/02/17 16:37:47 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/3f40521bf0214b42a0fbfa19fa3f2264/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 20/60 [28:05<58:11, 87.29s/trial, best loss: 0.5279504399227686]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.003725 seconds                       (0 + 1) / 1]\n",
      "TPE using 23/23 trials with best loss 0.527950\n",
      "2024/02/17 16:39:12 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/cfa7a6b917724986800dd19991b25ecd/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 21/60 [29:29<56:16, 86.58s/trial, best loss: 0.5279504399227686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.014530 seconds\n",
      "TPE using 24/24 trials with best loss 0.527950 23:>                 (0 + 1) / 1]\n",
      "2024/02/17 16:40:51 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/7f0a8e9621f64ec3ac644ce97846f12b/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 22/60 [31:02<56:03, 88.52s/trial, best loss: 0.51280440351991]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.003256 secondse 24:>                 (0 + 1) / 1]\n",
      "TPE using 25/25 trials with best loss 0.512804\n",
      "2024/02/17 16:43:22 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/ccad6d9a1bbb406da5655a928c89035d/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 23/60 [33:34<1:06:11, 107.33s/trial, best loss: 0.5122738079398443]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.014985 seconds\n",
      "TPE using 26/26 trials with best loss 0.512274\n",
      "2024/02/17 16:43:54 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/b846aa9fd3a944318e8231fa91bbd6b9/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 24/60 [34:07<51:05, 85.16s/trial, best loss: 0.5122738079398443]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.044216 seconds\n",
      "TPE using 27/27 trials with best loss 0.512274\n",
      "2024/02/17 16:46:24 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/850c55731e1c47cf8e172efbf6b02dcd/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 24:>                 (0 + 1) / 1][Stage 27:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 25/60 [36:37<1:01:02, 104.64s/trial, best loss: 0.5122738079398443]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.003735 seconds\n",
      "TPE using 28/28 trials with best loss 0.512274\n",
      "2024/02/17 16:46:45 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/b5b5531daf5f476abbcc0024c5b1238e/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 26/60 [37:01<45:31, 80.33s/trial, best loss: 0.5122738079398443]   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.035589 seconds                       (0 + 1) / 1]\n",
      "TPE using 29/29 trials with best loss 0.512274\n",
      "2024/02/17 16:47:44 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/0c4f621619cb45f8a4290c8ba20e5c42/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 27/60 [38:03<41:06, 74.74s/trial, best loss: 0.5122738079398443]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.066373 seconds                       (0 + 1) / 1]\n",
      "TPE using 30/30 trials with best loss 0.512274\n",
      "2024/02/17 16:53:51 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/ad7d1e22dad840b2a463cb242d8945c9/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 28:>                 (0 + 1) / 1][Stage 30:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 28/60 [44:04<1:25:48, 160.89s/trial, best loss: 0.5122738079398443]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.008146 seconds\n",
      "TPE using 31/31 trials with best loss 0.512274\n",
      "2024/02/17 16:54:25 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under /Users/hankehly/Projects/JapanHorseRaceAnalytics/mlruns/21/8585b8e72f9e44f2906aa8bd5a438dcb/artifacts. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 30:>                 (0 + 1) / 1][Stage 31:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 29/60 [44:50<1:05:16, 126.34s/trial, best loss: 0.5122738079398443]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.048672 seconds\n",
      "TPE using 32/32 trials with best loss 0.512274\n"
     ]
    }
   ],
   "source": [
    "trials_turf = SparkTrials(parallelism=3, spark_session=spark)\n",
    "fmin(fn=fn_turf, space=space, algo=tpe.suggest, max_evals=60, trials=trials_turf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
