{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"b3a27063-0145-4a10-8041-a9b46484d611\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"b3a27063-0145-4a10-8041-a9b46484d611\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.4.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"b3a27063-0145-4a10-8041-a9b46484d611\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import japanize_matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bokeh.io import output_notebook\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from JapanHorseRaceAnalytics.utilities.base import get_spark_session, read_hive_table\n",
    "from JapanHorseRaceAnalytics.utilities.structured_logger import logger\n",
    "\n",
    "# Set pandas display options\n",
    "pd.set_option(\"display.max_rows\", 1050)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "# Set seed for reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
    "np.random.seed(42)\n",
    "random_state = 42\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/04 08:21:22 WARN Utils: Your hostname, Hanks-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.40.105 instead (on interface en0)\n",
      "24/03/04 08:21:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "24/03/04 08:21:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"event\": \"Read from hive jhra_curated.features_20240217_v1\", \"level\": \"info\", \"timestamp\": \"2024-03-03T23:21:24.050524Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "24/03/04 08:21:24 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/04 08:21:24 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/04 08:21:25 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "{\"event\": \"Write to parquet /Users/hankehly/Projects/JapanHorseRaceAnalytics/data/sql_tables/features_20240217_v1.snappy.parquet\", \"level\": \"info\", \"timestamp\": \"2024-03-03T23:21:26.510146Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "24/03/04 08:21:26 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "{\"event\": \"Read from parquet /Users/hankehly/Projects/JapanHorseRaceAnalytics/data/sql_tables/features_20240217_v1.snappy.parquet to pandas\", \"level\": \"info\", \"timestamp\": \"2024-03-03T23:22:46.953876Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "{\"event\": \"Original data shape: (1108166, 1039)\", \"level\": \"info\", \"timestamp\": \"2024-03-03T23:23:02.778300Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "{\"event\": \"Data shape after filtering: (752305, 1039)\", \"level\": \"info\", \"timestamp\": \"2024-03-03T23:23:16.693925Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_馬番</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_本賞金</th>\n",
       "      <th>meta_単勝的中</th>\n",
       "      <th>meta_単勝払戻金</th>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <th>meta_複勝払戻金</th>\n",
       "      <th>meta_int_races_レースキー</th>\n",
       "      <th>meta_int_races_発走日時</th>\n",
       "      <th>meta_int_races_場コード</th>\n",
       "      <th>cat_四半期</th>\n",
       "      <th>cat_距離</th>\n",
       "      <th>cat_事前_馬場状態コード</th>\n",
       "      <th>num_事前_馬場差</th>\n",
       "      <th>cat_実績_馬場状態コード</th>\n",
       "      <th>num_実績_馬場差</th>\n",
       "      <th>cat_レース条件_記号</th>\n",
       "      <th>cat_レース条件_条件</th>\n",
       "      <th>cat_レース条件_重量</th>\n",
       "      <th>cat_レース条件_トラック情報_内外</th>\n",
       "      <th>cat_レース条件_トラック情報_右左</th>\n",
       "      <th>cat_レース条件_種別</th>\n",
       "      <th>cat_レース条件_グレード</th>\n",
       "      <th>cat_トラック種別</th>\n",
       "      <th>cat_馬場状態内</th>\n",
       "      <th>cat_馬場状態中</th>\n",
       "      <th>cat_馬場状態外</th>\n",
       "      <th>num_直線馬場差最内</th>\n",
       "      <th>num_直線馬場差内</th>\n",
       "      <th>num_直線馬場差中</th>\n",
       "      <th>num_直線馬場差外</th>\n",
       "      <th>num_直線馬場差大外</th>\n",
       "      <th>cat_芝種類</th>\n",
       "      <th>num_草丈</th>\n",
       "      <th>cat_転圧</th>\n",
       "      <th>cat_凍結防止剤</th>\n",
       "      <th>num_中間降水量</th>\n",
       "      <th>meta_int_race_horses_レースキー</th>\n",
       "      <th>meta_int_race_horses_馬番</th>\n",
       "      <th>meta_int_race_horses_血統登録番号</th>\n",
       "      <th>meta_int_race_horses_発走日時</th>\n",
       "      <th>meta_int_race_horses_異常区分</th>\n",
       "      <th>num_事前ＩＤＭ</th>\n",
       "      <th>cat_事前脚質</th>\n",
       "      <th>num_事前単勝オッズ</th>\n",
       "      <th>num_事前複勝オッズ</th>\n",
       "      <th>cat_事前馬体</th>\n",
       "      <th>cat_事前気配コード</th>\n",
       "      <th>cat_事前上昇度</th>\n",
       "      <th>cat_事前クラスコード</th>\n",
       "      <th>num_事前テン指数</th>\n",
       "      <th>num_事前ペース指数</th>\n",
       "      <th>num_事前上がり指数</th>\n",
       "      <th>num_負担重量</th>\n",
       "      <th>num_馬体重</th>\n",
       "      <th>num_馬体重増減</th>\n",
       "      <th>cat_性別</th>\n",
       "      <th>cat_トラック種別瞬発戦好走馬</th>\n",
       "      <th>cat_トラック種別消耗戦好走馬</th>\n",
       "      <th>num_一走前不利</th>\n",
       "      <th>num_二走前不利</th>\n",
       "      <th>num_三走前不利</th>\n",
       "      <th>num_一走前着順</th>\n",
       "      <th>num_二走前着順</th>\n",
       "      <th>num_三走前着順</th>\n",
       "      <th>num_四走前着順</th>\n",
       "      <th>num_五走前着順</th>\n",
       "      <th>num_六走前着順</th>\n",
       "      <th>num_1走前上昇度</th>\n",
       "      <th>num_2走前上昇度</th>\n",
       "      <th>num_3走前上昇度</th>\n",
       "      <th>num_4走前上昇度</th>\n",
       "      <th>num_5走前上昇度</th>\n",
       "      <th>num_騎手指数</th>\n",
       "      <th>num_情報指数</th>\n",
       "      <th>num_オッズ指数</th>\n",
       "      <th>num_パドック指数</th>\n",
       "      <th>num_総合指数</th>\n",
       "      <th>cat_馬具変更情報</th>\n",
       "      <th>cat_脚元情報</th>\n",
       "      <th>cat_見習い区分</th>\n",
       "      <th>cat_オッズ印</th>\n",
       "      <th>cat_パドック印</th>\n",
       "      <th>cat_直前総合印</th>\n",
       "      <th>cat_距離適性</th>\n",
       "      <th>num_ローテーション</th>\n",
       "      <th>num_基準オッズ</th>\n",
       "      <th>num_基準人気順位</th>\n",
       "      <th>num_基準複勝オッズ</th>\n",
       "      <th>num_基準複勝人気順位</th>\n",
       "      <th>num_特定情報◎</th>\n",
       "      <th>num_特定情報○</th>\n",
       "      <th>num_特定情報▲</th>\n",
       "      <th>num_特定情報△</th>\n",
       "      <th>num_特定情報×</th>\n",
       "      <th>num_総合情報◎</th>\n",
       "      <th>num_総合情報○</th>\n",
       "      <th>num_総合情報▲</th>\n",
       "      <th>...</th>\n",
       "      <th>num_競争相手平均調教師1位完走</th>\n",
       "      <th>num_競争相手調教師1位完走標準偏差</th>\n",
       "      <th>num_競争相手最高調教師トップ3完走</th>\n",
       "      <th>num_競争相手最低調教師トップ3完走</th>\n",
       "      <th>num_競争相手平均調教師トップ3完走</th>\n",
       "      <th>num_競争相手調教師トップ3完走標準偏差</th>\n",
       "      <th>num_競争相手最高調教師1位完走率</th>\n",
       "      <th>num_競争相手最低調教師1位完走率</th>\n",
       "      <th>num_競争相手平均調教師1位完走率</th>\n",
       "      <th>num_競争相手調教師1位完走率標準偏差</th>\n",
       "      <th>num_競争相手最高調教師トップ3完走率</th>\n",
       "      <th>num_競争相手最低調教師トップ3完走率</th>\n",
       "      <th>num_競争相手平均調教師トップ3完走率</th>\n",
       "      <th>num_競争相手調教師トップ3完走率標準偏差</th>\n",
       "      <th>num_競争相手最高調教師場所レース数</th>\n",
       "      <th>num_競争相手最低調教師場所レース数</th>\n",
       "      <th>num_競争相手平均調教師場所レース数</th>\n",
       "      <th>num_競争相手調教師場所レース数標準偏差</th>\n",
       "      <th>num_競争相手最高調教師場所1位完走</th>\n",
       "      <th>num_競争相手最低調教師場所1位完走</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走</th>\n",
       "      <th>num_競争相手調教師場所1位完走標準偏差</th>\n",
       "      <th>num_競争相手最高調教師場所トップ3完走</th>\n",
       "      <th>num_競争相手最低調教師場所トップ3完走</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走</th>\n",
       "      <th>num_競争相手調教師場所トップ3完走標準偏差</th>\n",
       "      <th>num_競争相手最高調教師場所1位完走率</th>\n",
       "      <th>num_競争相手最低調教師場所1位完走率</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走率</th>\n",
       "      <th>num_競争相手調教師場所1位完走率標準偏差</th>\n",
       "      <th>num_競争相手最高調教師場所トップ3完走率</th>\n",
       "      <th>num_競争相手最低調教師場所トップ3完走率</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走率</th>\n",
       "      <th>num_競争相手調教師場所トップ3完走率標準偏差</th>\n",
       "      <th>num_競争相手最高調教師本賞金累計</th>\n",
       "      <th>num_競争相手最低調教師本賞金累計</th>\n",
       "      <th>num_競争相手平均調教師本賞金累計</th>\n",
       "      <th>num_競争相手調教師本賞金累計標準偏差</th>\n",
       "      <th>num_競争相手最高調教師1位完走平均賞金</th>\n",
       "      <th>num_競争相手最低調教師1位完走平均賞金</th>\n",
       "      <th>num_競争相手平均調教師1位完走平均賞金</th>\n",
       "      <th>num_競争相手調教師1位完走平均賞金標準偏差</th>\n",
       "      <th>num_競争相手最高調教師レース数平均賞金</th>\n",
       "      <th>num_競争相手最低調教師レース数平均賞金</th>\n",
       "      <th>num_競争相手平均調教師レース数平均賞金</th>\n",
       "      <th>num_競争相手調教師レース数平均賞金標準偏差</th>\n",
       "      <th>num_競争相手平均調教師レース数差</th>\n",
       "      <th>num_競争相手平均調教師1位完走差</th>\n",
       "      <th>num_競争相手平均調教師トップ3完走差</th>\n",
       "      <th>num_競争相手平均調教師1位完走率差</th>\n",
       "      <th>num_競争相手平均調教師トップ3完走率差</th>\n",
       "      <th>num_競争相手平均調教師場所レース数差</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走差</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走差</th>\n",
       "      <th>num_競争相手平均調教師場所1位完走率差</th>\n",
       "      <th>num_競争相手平均調教師場所トップ3完走率差</th>\n",
       "      <th>num_競争相手平均調教師本賞金累計差</th>\n",
       "      <th>num_競争相手平均調教師1位完走平均賞金差</th>\n",
       "      <th>num_競争相手平均調教師レース数平均賞金差</th>\n",
       "      <th>meta_int_combinations_レースキー</th>\n",
       "      <th>meta_int_combinations_馬番</th>\n",
       "      <th>num_馬騎手レース数</th>\n",
       "      <th>num_馬騎手1位完走</th>\n",
       "      <th>num_馬騎手1位完走率</th>\n",
       "      <th>num_馬騎手トップ3完走</th>\n",
       "      <th>num_馬騎手トップ3完走率</th>\n",
       "      <th>num_馬騎手初二走</th>\n",
       "      <th>num_馬騎手同騎手</th>\n",
       "      <th>num_馬騎手場所レース数</th>\n",
       "      <th>num_馬騎手場所1位完走</th>\n",
       "      <th>num_馬騎手場所1位完走率</th>\n",
       "      <th>num_馬騎手場所トップ3完走</th>\n",
       "      <th>num_馬騎手場所トップ3完走率</th>\n",
       "      <th>num_馬調教師レース数</th>\n",
       "      <th>num_馬調教師1位完走</th>\n",
       "      <th>num_馬調教師1位完走率</th>\n",
       "      <th>num_馬調教師トップ3完走</th>\n",
       "      <th>num_馬調教師トップ3完走率</th>\n",
       "      <th>num_馬調教師初二走</th>\n",
       "      <th>num_馬調教師同調教師</th>\n",
       "      <th>num_馬調教師場所レース数</th>\n",
       "      <th>num_馬調教師場所1位完走</th>\n",
       "      <th>num_馬調教師場所1位完走率</th>\n",
       "      <th>num_馬調教師場所トップ3完走</th>\n",
       "      <th>num_馬調教師場所トップ3完走率</th>\n",
       "      <th>meta_int_race_weather_レースキー</th>\n",
       "      <th>num_temperature</th>\n",
       "      <th>num_precipitation</th>\n",
       "      <th>num_snowfall</th>\n",
       "      <th>num_snow_depth</th>\n",
       "      <th>num_wind_speed</th>\n",
       "      <th>cat_wind_direction</th>\n",
       "      <th>num_solar_radiation</th>\n",
       "      <th>num_local_air_pressure</th>\n",
       "      <th>num_sea_level_air_pressure</th>\n",
       "      <th>num_relative_humidity</th>\n",
       "      <th>num_vapor_pressure</th>\n",
       "      <th>num_dew_point_temperature</th>\n",
       "      <th>cat_weather</th>\n",
       "      <th>num_visibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2001-08-04 10:45:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01011103</td>\n",
       "      <td>2001-08-04 10:45:00+09:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>102</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>芝</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>98102049</td>\n",
       "      <td>2001-08-04 10:45:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>好位差し</td>\n",
       "      <td>11.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-12.4</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>550</td>\n",
       "      <td>476.0</td>\n",
       "      <td>14</td>\n",
       "      <td>牡</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>38.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>34.133333</td>\n",
       "      <td>18.575492</td>\n",
       "      <td>204</td>\n",
       "      <td>32</td>\n",
       "      <td>98.066667</td>\n",
       "      <td>44.395896</td>\n",
       "      <td>0.162376</td>\n",
       "      <td>0.027668</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.036725</td>\n",
       "      <td>0.403960</td>\n",
       "      <td>0.120735</td>\n",
       "      <td>0.213261</td>\n",
       "      <td>0.076365</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>18.733333</td>\n",
       "      <td>12.390677</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.112397</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>4.464178</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094180</td>\n",
       "      <td>0.088041</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207743</td>\n",
       "      <td>0.136352</td>\n",
       "      <td>231606.0</td>\n",
       "      <td>14187.0</td>\n",
       "      <td>65859.266667</td>\n",
       "      <td>53242.331542</td>\n",
       "      <td>1687.439024</td>\n",
       "      <td>567.857143</td>\n",
       "      <td>913.419366</td>\n",
       "      <td>273.792817</td>\n",
       "      <td>458.625743</td>\n",
       "      <td>49.167979</td>\n",
       "      <td>141.408061</td>\n",
       "      <td>101.993179</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>-3.133333</td>\n",
       "      <td>-5.066667</td>\n",
       "      <td>-0.016287</td>\n",
       "      <td>-0.036119</td>\n",
       "      <td>-6.733333</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>-0.010847</td>\n",
       "      <td>0.125590</td>\n",
       "      <td>-18662.266667</td>\n",
       "      <td>-159.225818</td>\n",
       "      <td>-51.509013</td>\n",
       "      <td>01011103</td>\n",
       "      <td>04</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>01011103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2001-08-11 10:45:00+09:00</td>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>1090</td>\n",
       "      <td>01011303</td>\n",
       "      <td>2001-08-11 10:45:00+09:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1700</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>002</td>\n",
       "      <td>A3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>98103267</td>\n",
       "      <td>2001-08-11 10:45:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>差し</td>\n",
       "      <td>50.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>-24.3</td>\n",
       "      <td>-28.8</td>\n",
       "      <td>550</td>\n",
       "      <td>436.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>牡</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>13</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>16.573699</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "      <td>122.250000</td>\n",
       "      <td>44.358624</td>\n",
       "      <td>0.096825</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.064903</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.294828</td>\n",
       "      <td>0.121359</td>\n",
       "      <td>0.208923</td>\n",
       "      <td>0.055122</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>19.472737</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.838231</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>8.083333</td>\n",
       "      <td>7.193265</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053959</td>\n",
       "      <td>0.048886</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.256171</td>\n",
       "      <td>0.157059</td>\n",
       "      <td>172151.0</td>\n",
       "      <td>24692.0</td>\n",
       "      <td>77010.125000</td>\n",
       "      <td>41784.766816</td>\n",
       "      <td>1655.294118</td>\n",
       "      <td>716.296296</td>\n",
       "      <td>972.226859</td>\n",
       "      <td>235.029654</td>\n",
       "      <td>296.812069</td>\n",
       "      <td>59.932039</td>\n",
       "      <td>130.679572</td>\n",
       "      <td>63.348222</td>\n",
       "      <td>-41.333333</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0.033582</td>\n",
       "      <td>0.063804</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>7.916667</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.115922</td>\n",
       "      <td>-1223.125000</td>\n",
       "      <td>-199.919166</td>\n",
       "      <td>12.856413</td>\n",
       "      <td>01011303</td>\n",
       "      <td>06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>01011303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01011612</td>\n",
       "      <td>04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2001-08-19 16:10:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01011612</td>\n",
       "      <td>2001-08-19 16:10:00+09:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01011612</td>\n",
       "      <td>04</td>\n",
       "      <td>98103187</td>\n",
       "      <td>2001-08-19 16:10:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>逃げ</td>\n",
       "      <td>19.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>530</td>\n",
       "      <td>434.0</td>\n",
       "      <td>-10</td>\n",
       "      <td>牝</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.545455</td>\n",
       "      <td>16.411546</td>\n",
       "      <td>198</td>\n",
       "      <td>44</td>\n",
       "      <td>120.545455</td>\n",
       "      <td>42.322063</td>\n",
       "      <td>0.111643</td>\n",
       "      <td>0.050881</td>\n",
       "      <td>0.077207</td>\n",
       "      <td>0.020627</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.176580</td>\n",
       "      <td>0.231478</td>\n",
       "      <td>0.039257</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>24.090909</td>\n",
       "      <td>15.017896</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>1.966664</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>3.703918</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091959</td>\n",
       "      <td>0.083872</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.275630</td>\n",
       "      <td>0.122950</td>\n",
       "      <td>120442.0</td>\n",
       "      <td>20946.0</td>\n",
       "      <td>70885.909091</td>\n",
       "      <td>29646.013260</td>\n",
       "      <td>1205.609756</td>\n",
       "      <td>746.562500</td>\n",
       "      <td>905.224659</td>\n",
       "      <td>133.843063</td>\n",
       "      <td>191.498405</td>\n",
       "      <td>89.223048</td>\n",
       "      <td>134.708340</td>\n",
       "      <td>35.588154</td>\n",
       "      <td>361.454545</td>\n",
       "      <td>21.454545</td>\n",
       "      <td>54.454545</td>\n",
       "      <td>-0.006592</td>\n",
       "      <td>-0.032161</td>\n",
       "      <td>-3.090909</td>\n",
       "      <td>-1.363636</td>\n",
       "      <td>-1.090909</td>\n",
       "      <td>-0.044340</td>\n",
       "      <td>-0.037535</td>\n",
       "      <td>40733.090909</td>\n",
       "      <td>36.065664</td>\n",
       "      <td>-7.579639</td>\n",
       "      <td>01011612</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>01011612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01012112</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2001-09-01 16:10:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01012112</td>\n",
       "      <td>2001-09-01 16:10:00+09:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1200</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>102</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>芝</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01012112</td>\n",
       "      <td>11</td>\n",
       "      <td>97103998</td>\n",
       "      <td>2001-09-01 16:10:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>逃げ</td>\n",
       "      <td>14.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>530</td>\n",
       "      <td>516.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>牝</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>40.714286</td>\n",
       "      <td>22.864285</td>\n",
       "      <td>216</td>\n",
       "      <td>32</td>\n",
       "      <td>115.928571</td>\n",
       "      <td>46.773717</td>\n",
       "      <td>0.209901</td>\n",
       "      <td>0.027073</td>\n",
       "      <td>0.076665</td>\n",
       "      <td>0.042664</td>\n",
       "      <td>0.427723</td>\n",
       "      <td>0.115059</td>\n",
       "      <td>0.216003</td>\n",
       "      <td>0.075855</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>36.714286</td>\n",
       "      <td>15.709090</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.591194</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>9.642857</td>\n",
       "      <td>6.353932</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.087344</td>\n",
       "      <td>0.062180</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.258424</td>\n",
       "      <td>0.090050</td>\n",
       "      <td>178871.0</td>\n",
       "      <td>14187.0</td>\n",
       "      <td>71188.285714</td>\n",
       "      <td>39861.027438</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>664.375000</td>\n",
       "      <td>907.348688</td>\n",
       "      <td>248.437087</td>\n",
       "      <td>354.200000</td>\n",
       "      <td>52.544444</td>\n",
       "      <td>132.234042</td>\n",
       "      <td>71.661732</td>\n",
       "      <td>-111.357143</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>-2.928571</td>\n",
       "      <td>0.020722</td>\n",
       "      <td>0.052405</td>\n",
       "      <td>-13.714286</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.173526</td>\n",
       "      <td>0.263315</td>\n",
       "      <td>4172.714286</td>\n",
       "      <td>298.261068</td>\n",
       "      <td>46.770709</td>\n",
       "      <td>01012112</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>01012112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01012208</td>\n",
       "      <td>01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2001-09-02 13:45:00+09:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>01012208</td>\n",
       "      <td>2001-09-02 13:45:00+09:00</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>1700</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>003</td>\n",
       "      <td>05</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01012208</td>\n",
       "      <td>01</td>\n",
       "      <td>97105757</td>\n",
       "      <td>2001-09-02 13:45:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>差し</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>570</td>\n",
       "      <td>414.0</td>\n",
       "      <td>-8</td>\n",
       "      <td>牡</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>37.700000</td>\n",
       "      <td>25.507058</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>119.400000</td>\n",
       "      <td>59.282712</td>\n",
       "      <td>0.151560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064854</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>0.355126</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206888</td>\n",
       "      <td>0.093646</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>40.300000</td>\n",
       "      <td>21.255823</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.061553</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>6.232977</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085076</td>\n",
       "      <td>0.051316</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.240003</td>\n",
       "      <td>0.110983</td>\n",
       "      <td>167371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69521.150000</td>\n",
       "      <td>44905.095448</td>\n",
       "      <td>1226.896552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>780.579546</td>\n",
       "      <td>297.965063</td>\n",
       "      <td>249.585849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.169680</td>\n",
       "      <td>72.223019</td>\n",
       "      <td>15.900000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>-13.400000</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>-0.006888</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>-9151.650000</td>\n",
       "      <td>-1.500598</td>\n",
       "      <td>-6.264963</td>\n",
       "      <td>01012208</td>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>4</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>01012208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_レースキー meta_馬番  meta_着順                 meta_発走日時  meta_本賞金  meta_単勝的中  \\\n",
       "0   01011103      04      6.0 2001-08-04 10:45:00+09:00       0.0      False   \n",
       "1   01011303      06      3.0 2001-08-11 10:45:00+09:00     130.0      False   \n",
       "2   01011612      04      9.0 2001-08-19 16:10:00+09:00       0.0      False   \n",
       "3   01012112      11      6.0 2001-09-01 16:10:00+09:00       0.0      False   \n",
       "4   01012208      01      6.0 2001-09-02 13:45:00+09:00       0.0      False   \n",
       "\n",
       "   meta_単勝払戻金  meta_複勝的中  meta_複勝払戻金 meta_int_races_レースキー  \\\n",
       "0           0      False           0             01011103   \n",
       "1           0       True        1090             01011303   \n",
       "2           0      False           0             01011612   \n",
       "3           0      False           0             01012112   \n",
       "4           0      False           0             01012208   \n",
       "\n",
       "         meta_int_races_発走日時 meta_int_races_場コード  cat_四半期  cat_距離  \\\n",
       "0  2001-08-04 10:45:00+09:00                  01        3    1200   \n",
       "1  2001-08-11 10:45:00+09:00                  01        3    1700   \n",
       "2  2001-08-19 16:10:00+09:00                  01        3    1000   \n",
       "3  2001-09-01 16:10:00+09:00                  01        3    1200   \n",
       "4  2001-09-02 13:45:00+09:00                  01        3    1700   \n",
       "\n",
       "  cat_事前_馬場状態コード  num_事前_馬場差 cat_実績_馬場状態コード  num_実績_馬場差 cat_レース条件_記号  \\\n",
       "0             20         NaN             21       -18.0          102   \n",
       "1             10         NaN             11       -19.0          002   \n",
       "2             10         NaN             11       -20.0          103   \n",
       "3             10         NaN             10         3.0          102   \n",
       "4             10         NaN             11       -14.0          003   \n",
       "\n",
       "  cat_レース条件_条件 cat_レース条件_重量 cat_レース条件_トラック情報_内外 cat_レース条件_トラック情報_右左  \\\n",
       "0           A3            3                   1                   1   \n",
       "1           A3            3                   1                   1   \n",
       "2           10            2                   1                   1   \n",
       "3           10            1                   1                   1   \n",
       "4           05            2                   1                   1   \n",
       "\n",
       "  cat_レース条件_種別 cat_レース条件_グレード cat_トラック種別 cat_馬場状態内 cat_馬場状態中 cat_馬場状態外  \\\n",
       "0           12           None          芝         1         1         1   \n",
       "1           12           None        ダート         1         1         1   \n",
       "2           13              5        ダート         1         1         1   \n",
       "3           13              5          芝         2         1         1   \n",
       "4           13           None        ダート         1         1         1   \n",
       "\n",
       "   num_直線馬場差最内  num_直線馬場差内  num_直線馬場差中  num_直線馬場差外  num_直線馬場差大外 cat_芝種類  \\\n",
       "0            1           1           0           0            0    None   \n",
       "1            1           1           0           0            0    None   \n",
       "2            0           0           0           0            0    None   \n",
       "3            2           1           0           0            0    None   \n",
       "4            2           1           0           0            0    None   \n",
       "\n",
       "   num_草丈  cat_転圧  cat_凍結防止剤  num_中間降水量 meta_int_race_horses_レースキー  \\\n",
       "0     NaN   False      False        NaN                   01011103   \n",
       "1     NaN   False      False        NaN                   01011303   \n",
       "2     NaN   False      False        NaN                   01011612   \n",
       "3     NaN   False      False        NaN                   01012112   \n",
       "4     NaN   False      False        NaN                   01012208   \n",
       "\n",
       "  meta_int_race_horses_馬番 meta_int_race_horses_血統登録番号  \\\n",
       "0                      04                    98102049   \n",
       "1                      06                    98103267   \n",
       "2                      04                    98103187   \n",
       "3                      11                    97103998   \n",
       "4                      01                    97105757   \n",
       "\n",
       "   meta_int_race_horses_発走日時 meta_int_race_horses_異常区分  num_事前ＩＤＭ cat_事前脚質  \\\n",
       "0  2001-08-04 10:45:00+09:00                         0       36.0     好位差し   \n",
       "1  2001-08-11 10:45:00+09:00                         0       17.0       差し   \n",
       "2  2001-08-19 16:10:00+09:00                         0       40.0       逃げ   \n",
       "3  2001-09-01 16:10:00+09:00                         0       52.0       逃げ   \n",
       "4  2001-09-02 13:45:00+09:00                         0       36.0       差し   \n",
       "\n",
       "   num_事前単勝オッズ  num_事前複勝オッズ cat_事前馬体 cat_事前気配コード cat_事前上昇度 cat_事前クラスコード  \\\n",
       "0         11.5          2.9     None        None         3           18   \n",
       "1         50.8          8.7     None        None         3           18   \n",
       "2         19.9          5.0     None        None         3           12   \n",
       "3         14.3          5.0     None        None         3           35   \n",
       "4          7.3          2.4     None        None         3           35   \n",
       "\n",
       "   num_事前テン指数  num_事前ペース指数  num_事前上がり指数  num_負担重量  num_馬体重  num_馬体重増減 cat_性別  \\\n",
       "0       -12.4        -21.1        -10.9       550    476.0         14      牡   \n",
       "1        -8.4        -24.3        -28.8       550    436.0         -4      牡   \n",
       "2        -2.3        -13.7         -6.0       530    434.0        -10      牝   \n",
       "3         0.1         -3.3        -11.9       530    516.0         -4      牝   \n",
       "4        -9.6         -5.4        -15.9       570    414.0         -8      牡   \n",
       "\n",
       "   cat_トラック種別瞬発戦好走馬  cat_トラック種別消耗戦好走馬  num_一走前不利  num_二走前不利  num_三走前不利  \\\n",
       "0              True             False        0.0        0.0        0.0   \n",
       "1             False             False        1.0        0.0        0.0   \n",
       "2              True             False        0.0        0.0        0.0   \n",
       "3              True             False        0.0        0.0        0.0   \n",
       "4              True             False        0.0        0.0        0.0   \n",
       "\n",
       "   num_一走前着順  num_二走前着順  num_三走前着順  num_四走前着順  num_五走前着順  num_六走前着順  \\\n",
       "0        7.0        2.0        7.0        NaN        NaN        NaN   \n",
       "1       12.0       13.0        7.0        NaN        NaN        NaN   \n",
       "2       10.0        7.0        1.0        NaN        NaN        NaN   \n",
       "3        6.0        1.0        8.0        NaN        NaN        NaN   \n",
       "4        7.0        2.0        6.0       10.0        4.0        NaN   \n",
       "\n",
       "  num_1走前上昇度 num_2走前上昇度 num_3走前上昇度 num_4走前上昇度 num_5走前上昇度  num_騎手指数  num_情報指数  \\\n",
       "0          3          3          3       None       None       0.4       0.4   \n",
       "1          3          3          3       None       None       0.3      -1.0   \n",
       "2          3          3          3       None       None       0.1       0.0   \n",
       "3          3          3          2       None       None       0.8       0.8   \n",
       "4          3          3          3          3          3       1.1       2.9   \n",
       "\n",
       "   num_オッズ指数  num_パドック指数  num_総合指数 cat_馬具変更情報 cat_脚元情報 cat_見習い区分 cat_オッズ印  \\\n",
       "0        0.0         1.8      38.6          0        0         0     None   \n",
       "1        0.0         0.0      16.3          0        0         0     None   \n",
       "2        0.0         0.0      40.1          0        0         0     None   \n",
       "3        1.5         0.0      55.1          0        0         0        5   \n",
       "4        1.5         2.0      43.5          0        0         0        5   \n",
       "\n",
       "  cat_パドック印 cat_直前総合印 cat_距離適性  num_ローテーション  num_基準オッズ  num_基準人気順位  \\\n",
       "0         4         4        5          4.0       16.8           6   \n",
       "1      None      None        5          0.0       89.5          13   \n",
       "2      None      None        1          2.0       31.9           9   \n",
       "3      None      None        1          1.0       16.2           7   \n",
       "4         3         3        5          0.0        7.1           4   \n",
       "\n",
       "   num_基準複勝オッズ  num_基準複勝人気順位  num_特定情報◎  num_特定情報○  num_特定情報▲  num_特定情報△  \\\n",
       "0          3.4             6          0          0          0         10   \n",
       "1         14.5            13          0          0          0          0   \n",
       "2          6.5             9          0          0          0          6   \n",
       "3          4.0             7          0          0          0          5   \n",
       "4          2.0             3          0          0          3          8   \n",
       "\n",
       "   num_特定情報×  num_総合情報◎  num_総合情報○  num_総合情報▲  ...  num_競争相手平均調教師1位完走  \\\n",
       "0          0          3          6          8  ...          34.133333   \n",
       "1          0          0          0          0  ...          38.250000   \n",
       "2          0          0          0          3  ...          40.545455   \n",
       "3          0         11          3          7  ...          40.714286   \n",
       "4          0          8          9         25  ...          37.700000   \n",
       "\n",
       "   num_競争相手調教師1位完走標準偏差  num_競争相手最高調教師トップ3完走  num_競争相手最低調教師トップ3完走  \\\n",
       "0            18.575492                  204                   32   \n",
       "1            16.573699                  180                   50   \n",
       "2            16.411546                  198                   44   \n",
       "3            22.864285                  216                   32   \n",
       "4            25.507058                  239                    0   \n",
       "\n",
       "   num_競争相手平均調教師トップ3完走 num_競争相手調教師トップ3完走標準偏差 num_競争相手最高調教師1位完走率  \\\n",
       "0            98.066667             44.395896           0.162376   \n",
       "1           122.250000             44.358624           0.096825   \n",
       "2           120.545455             42.322063           0.111643   \n",
       "3           115.928571             46.773717           0.209901   \n",
       "4           119.400000             59.282712           0.151560   \n",
       "\n",
       "   num_競争相手最低調教師1位完走率  num_競争相手平均調教師1位完走率 num_競争相手調教師1位完走率標準偏差  \\\n",
       "0            0.027668            0.075334             0.036725   \n",
       "1            0.029126            0.064903             0.022876   \n",
       "2            0.050881            0.077207             0.020627   \n",
       "3            0.027073            0.076665             0.042664   \n",
       "4            0.000000            0.064854             0.038882   \n",
       "\n",
       "  num_競争相手最高調教師トップ3完走率 num_競争相手最低調教師トップ3完走率 num_競争相手平均調教師トップ3完走率  \\\n",
       "0             0.403960             0.120735             0.213261   \n",
       "1             0.294828             0.121359             0.208923   \n",
       "2             0.291866             0.176580             0.231478   \n",
       "3             0.427723             0.115059             0.216003   \n",
       "4             0.355126             0.000000             0.206888   \n",
       "\n",
       "  num_競争相手調教師トップ3完走率標準偏差 num_競争相手最高調教師場所レース数 num_競争相手最低調教師場所レース数  \\\n",
       "0               0.076365                  47                   3   \n",
       "1               0.055122                  65                   2   \n",
       "2               0.039257                  61                   3   \n",
       "3               0.075855                  64                  16   \n",
       "4               0.093646                  79                   2   \n",
       "\n",
       "  num_競争相手平均調教師場所レース数 num_競争相手調教師場所レース数標準偏差  num_競争相手最高調教師場所1位完走  \\\n",
       "0           18.733333             12.390677                    8   \n",
       "1           35.250000             19.472737                   10   \n",
       "2           24.090909             15.017896                    6   \n",
       "3           36.714286             15.709090                   11   \n",
       "4           40.300000             21.255823                    6   \n",
       "\n",
       "   num_競争相手最低調教師場所1位完走 num_競争相手平均調教師場所1位完走  num_競争相手調教師場所1位完走標準偏差  \\\n",
       "0                    0            2.066667               2.112397   \n",
       "1                    0            2.666667               2.838231   \n",
       "2                    0            2.363636               1.966664   \n",
       "3                    1            3.000000               2.591194   \n",
       "4                    0            3.500000               2.061553   \n",
       "\n",
       "   num_競争相手最高調教師場所トップ3完走 num_競争相手最低調教師場所トップ3完走  num_競争相手平均調教師場所トップ3完走  \\\n",
       "0                     15                     0               4.733333   \n",
       "1                     20                     1               8.083333   \n",
       "2                     12                     1               6.090909   \n",
       "3                     26                     3               9.642857   \n",
       "4                     21                     0              10.500000   \n",
       "\n",
       "   num_競争相手調教師場所トップ3完走標準偏差 num_競争相手最高調教師場所1位完走率  num_競争相手最低調教師場所1位完走率  \\\n",
       "0                 4.464178             0.333333              0.000000   \n",
       "1                 7.193265             0.153846              0.000000   \n",
       "2                 3.703918             0.300000              0.000000   \n",
       "3                 6.353932             0.250000              0.017857   \n",
       "4                 6.232977             0.153846              0.000000   \n",
       "\n",
       "   num_競争相手平均調教師場所1位完走率 num_競争相手調教師場所1位完走率標準偏差 num_競争相手最高調教師場所トップ3完走率  \\\n",
       "0              0.094180               0.088041                0.50000   \n",
       "1              0.053959               0.048886                0.50000   \n",
       "2              0.091959               0.083872                0.60000   \n",
       "3              0.087344               0.062180                0.40625   \n",
       "4              0.085076               0.051316                0.37931   \n",
       "\n",
       "   num_競争相手最低調教師場所トップ3完走率  num_競争相手平均調教師場所トップ3完走率  num_競争相手調教師場所トップ3完走率標準偏差  \\\n",
       "0                0.000000                0.207743                  0.136352   \n",
       "1                0.039216                0.256171                  0.157059   \n",
       "2                0.076923                0.275630                  0.122950   \n",
       "3                0.102564                0.258424                  0.090050   \n",
       "4                0.000000                0.240003                  0.110983   \n",
       "\n",
       "   num_競争相手最高調教師本賞金累計  num_競争相手最低調教師本賞金累計  num_競争相手平均調教師本賞金累計  \\\n",
       "0            231606.0             14187.0        65859.266667   \n",
       "1            172151.0             24692.0        77010.125000   \n",
       "2            120442.0             20946.0        70885.909091   \n",
       "3            178871.0             14187.0        71188.285714   \n",
       "4            167371.0                 0.0        69521.150000   \n",
       "\n",
       "   num_競争相手調教師本賞金累計標準偏差  num_競争相手最高調教師1位完走平均賞金 num_競争相手最低調教師1位完走平均賞金  \\\n",
       "0          53242.331542            1687.439024            567.857143   \n",
       "1          41784.766816            1655.294118            716.296296   \n",
       "2          29646.013260            1205.609756            746.562500   \n",
       "3          39861.027438            1685.000000            664.375000   \n",
       "4          44905.095448            1226.896552              0.000000   \n",
       "\n",
       "   num_競争相手平均調教師1位完走平均賞金  num_競争相手調教師1位完走平均賞金標準偏差  num_競争相手最高調教師レース数平均賞金  \\\n",
       "0             913.419366               273.792817             458.625743   \n",
       "1             972.226859               235.029654             296.812069   \n",
       "2             905.224659               133.843063             191.498405   \n",
       "3             907.348688               248.437087             354.200000   \n",
       "4             780.579546               297.965063             249.585849   \n",
       "\n",
       "  num_競争相手最低調教師レース数平均賞金 num_競争相手平均調教師レース数平均賞金 num_競争相手調教師レース数平均賞金標準偏差  \\\n",
       "0             49.167979            141.408061              101.993179   \n",
       "1             59.932039            130.679572               63.348222   \n",
       "2             89.223048            134.708340               35.588154   \n",
       "3             52.544444            132.234042               71.661732   \n",
       "4              0.000000            120.169680               72.223019   \n",
       "\n",
       "  num_競争相手平均調教師レース数差 num_競争相手平均調教師1位完走差 num_競争相手平均調教師トップ3完走差  \\\n",
       "0          73.000000          -3.133333            -5.066667   \n",
       "1         -41.333333          13.750000            21.750000   \n",
       "2         361.454545          21.454545            54.454545   \n",
       "3        -111.357143           0.285714            -2.928571   \n",
       "4          15.900000           0.300000           -13.400000   \n",
       "\n",
       "  num_競争相手平均調教師1位完走率差 num_競争相手平均調教師トップ3完走率差 num_競争相手平均調教師場所レース数差  \\\n",
       "0           -0.016287             -0.036119            -6.733333   \n",
       "1            0.033582              0.063804             7.750000   \n",
       "2           -0.006592             -0.032161            -3.090909   \n",
       "3            0.020722              0.052405           -13.714286   \n",
       "4            0.006844             -0.006888             1.700000   \n",
       "\n",
       "  num_競争相手平均調教師場所1位完走差 num_競争相手平均調教師場所トップ3完走差 num_競争相手平均調教師場所1位完走率差  \\\n",
       "0            -1.066667              -0.733333             -0.010847   \n",
       "1             1.333333               7.916667              0.039064   \n",
       "2            -1.363636              -1.090909             -0.044340   \n",
       "3             3.000000               2.357143              0.173526   \n",
       "4             0.500000              -0.500000              0.010162   \n",
       "\n",
       "  num_競争相手平均調教師場所トップ3完走率差 num_競争相手平均調教師本賞金累計差  num_競争相手平均調教師1位完走平均賞金差  \\\n",
       "0                0.125590       -18662.266667             -159.225818   \n",
       "1                0.115922        -1223.125000             -199.919166   \n",
       "2               -0.037535        40733.090909               36.065664   \n",
       "3                0.263315         4172.714286              298.261068   \n",
       "4               -0.001907        -9151.650000               -1.500598   \n",
       "\n",
       "  num_競争相手平均調教師レース数平均賞金差 meta_int_combinations_レースキー  \\\n",
       "0             -51.509013                    01011103   \n",
       "1              12.856413                    01011303   \n",
       "2              -7.579639                    01011612   \n",
       "3              46.770709                    01012112   \n",
       "4              -6.264963                    01012208   \n",
       "\n",
       "   meta_int_combinations_馬番  num_馬騎手レース数 num_馬騎手1位完走 num_馬騎手1位完走率  \\\n",
       "0                        04            2           0          0.0   \n",
       "1                        06            1           0          0.0   \n",
       "2                        04            0           0          0.0   \n",
       "3                        11            4           2          0.5   \n",
       "4                        01            0           0          0.0   \n",
       "\n",
       "   num_馬騎手トップ3完走  num_馬騎手トップ3完走率  num_馬騎手初二走  num_馬騎手同騎手  num_馬騎手場所レース数  \\\n",
       "0              0             0.0       False       False              0   \n",
       "1              0             0.0        True        True              1   \n",
       "2              0             0.0        True       False              0   \n",
       "3              2             0.5       False       False              1   \n",
       "4              0             0.0        True       False              0   \n",
       "\n",
       "   num_馬騎手場所1位完走  num_馬騎手場所1位完走率  num_馬騎手場所トップ3完走  num_馬騎手場所トップ3完走率  \\\n",
       "0              0             0.0                0               0.0   \n",
       "1              0             0.0                0               0.0   \n",
       "2              0             0.0                0               0.0   \n",
       "3              1             1.0                1               1.0   \n",
       "4              0             0.0                0               0.0   \n",
       "\n",
       "   num_馬調教師レース数  num_馬調教師1位完走  num_馬調教師1位完走率  num_馬調教師トップ3完走  num_馬調教師トップ3完走率  \\\n",
       "0             9             0       0.000000               1         0.111111   \n",
       "1             5             0       0.000000               0         0.000000   \n",
       "2            12             2       0.166667               4         0.333333   \n",
       "3            10             3       0.300000               5         0.500000   \n",
       "4            21             2       0.095238               4         0.190476   \n",
       "\n",
       "  num_馬調教師初二走 num_馬調教師同調教師  num_馬調教師場所レース数  num_馬調教師場所1位完走  num_馬調教師場所1位完走率  \\\n",
       "0       False         True               0               0         0.000000   \n",
       "1       False         True               1               0         0.000000   \n",
       "2       False         True               0               0         0.000000   \n",
       "3       False         True               2               1         0.500000   \n",
       "4       False         True               3               1         0.333333   \n",
       "\n",
       "   num_馬調教師場所トップ3完走  num_馬調教師場所トップ3完走率  meta_int_race_weather_レースキー  \\\n",
       "0                 0           0.000000                     01011103   \n",
       "1                 0           0.000000                     01011303   \n",
       "2                 0           0.000000                     01011612   \n",
       "3                 1           0.500000                     01012112   \n",
       "4                 1           0.333333                     01012208   \n",
       "\n",
       "   num_temperature  num_precipitation  num_snowfall  num_snow_depth  \\\n",
       "0              NaN                NaN           NaN             NaN   \n",
       "1              NaN                NaN           NaN             NaN   \n",
       "2              NaN                NaN           NaN             NaN   \n",
       "3              NaN                NaN           NaN             NaN   \n",
       "4              NaN                NaN           NaN             NaN   \n",
       "\n",
       "   num_wind_speed  cat_wind_direction  num_solar_radiation  \\\n",
       "0             NaN                None                  NaN   \n",
       "1             NaN                None                  NaN   \n",
       "2             NaN                None                  NaN   \n",
       "3             NaN                None                  NaN   \n",
       "4             NaN                None                  NaN   \n",
       "\n",
       "   num_local_air_pressure  num_sea_level_air_pressure  num_relative_humidity  \\\n",
       "0                     NaN                         NaN                    NaN   \n",
       "1                     NaN                         NaN                    NaN   \n",
       "2                     NaN                         NaN                    NaN   \n",
       "3                     NaN                         NaN                    NaN   \n",
       "4                     NaN                         NaN                    NaN   \n",
       "\n",
       "   num_vapor_pressure  num_dew_point_temperature  cat_weather  num_visibility  \n",
       "0                 NaN                        NaN         None             NaN  \n",
       "1                 NaN                        NaN         None             NaN  \n",
       "2                 NaN                        NaN         None             NaN  \n",
       "3                 NaN                        NaN         None             NaN  \n",
       "4                 NaN                        NaN         None             NaN  \n",
       "\n",
       "[5 rows x 1039 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_hive_table(\n",
    "    table_name=\"features_20240217_v1\",\n",
    "    schema=\"jhra_curated\",\n",
    "    spark_session=spark,\n",
    "    use_cache=False,\n",
    "    parse_dates=[\"meta_発走日時\"],\n",
    ")\n",
    "\n",
    "logger.info(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "# drop from data where cat_トラック種別 == \"障害\"\n",
    "data = data[(data[\"cat_トラック種別\"] != \"障害\")]\n",
    "\n",
    "# drop from data where meta_int_race_horses_異常区分 != '0'\n",
    "data = data[(data[\"meta_int_race_horses_異常区分\"] == \"0\")]\n",
    "\n",
    "# keep only horses that have 3 races\n",
    "data = data[\n",
    "    (data[\"num_一走前着順\"].notnull())\n",
    "    & (data[\"num_二走前着順\"].notnull())\n",
    "    & (data[\"num_三走前着順\"].notnull())\n",
    "]\n",
    "\n",
    "logger.info(f\"Data shape after filtering: {data.shape}\")\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: Horses that finish in higher positions in the past 3 races, with the last race being most impactful, are more likely to finish in higher positions in the next race.\n",
    "\n",
    "* True\n",
    "\n",
    "**How to use:** Get the normalized position of the past 3 races and multiply them by the weights. Then sum the results to get the final score. This feature correlates with the target by 0.3.\n",
    "\n",
    "```python\n",
    "weights = {\"num_一走前着順\": 0.2927557, \"num_二走前着順\": 0.14651419, \"num_三走前着順\": 0.10043724}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights (determined with linear regression): {'num_一走前着順': 0.2927557, 'num_二走前着順': 0.14651419, 'num_三走前着順': 0.10043724}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Placed 3 races ago</th>\n",
       "      <th>Placed 2 races ago</th>\n",
       "      <th>Placed 1 race ago</th>\n",
       "      <th>Placed in Current Race</th>\n",
       "      <th>Weighted Score</th>\n",
       "      <th>Weighted Score 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12.821418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.541433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32.840108</td>\n",
       "      <td>29.275570</td>\n",
       "      <td>85.229887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25.008945</td>\n",
       "      <td>14.651419</td>\n",
       "      <td>78.752068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>41.125818</td>\n",
       "      <td>43.926989</td>\n",
       "      <td>91.932489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21.619492</td>\n",
       "      <td>10.043724</td>\n",
       "      <td>74.997133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>39.025929</td>\n",
       "      <td>39.319294</td>\n",
       "      <td>90.307662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30.532976</td>\n",
       "      <td>24.695143</td>\n",
       "      <td>83.292180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>45.927018</td>\n",
       "      <td>53.970713</td>\n",
       "      <td>95.953758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Placed 3 races ago  Placed 2 races ago  Placed 1 race ago  \\\n",
       "0               False               False              False   \n",
       "1               False               False               True   \n",
       "2               False                True              False   \n",
       "3               False                True               True   \n",
       "4                True               False              False   \n",
       "5                True               False               True   \n",
       "6                True                True              False   \n",
       "7                True                True               True   \n",
       "\n",
       "   Placed in Current Race  Weighted Score  Weighted Score 2  \n",
       "0               12.821418        0.000000         67.541433  \n",
       "1               32.840108       29.275570         85.229887  \n",
       "2               25.008945       14.651419         78.752068  \n",
       "3               41.125818       43.926989         91.932489  \n",
       "4               21.619492       10.043724         74.997133  \n",
       "5               39.025929       39.319294         90.307662  \n",
       "6               30.532976       24.695143         83.292180  \n",
       "7               45.927018       53.970713         95.953758  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/04 09:02:16 WARN HikariPool: HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m19s575ms).\n",
      "24/03/04 09:02:16 WARN HikariPool: HikariPool-2 - Thread starvation or clock leap detected (housekeeper delta=1m19s572ms).\n",
      "24/03/04 09:03:44 WARN HikariPool: HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=1m27s373ms).\n",
      "24/03/04 09:03:44 WARN HikariPool: HikariPool-2 - Thread starvation or clock leap detected (housekeeper delta=1m27s373ms).\n",
      "24/03/04 09:06:50 WARN HikariPool: HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=2m35s983ms).\n",
      "24/03/04 09:06:50 WARN HikariPool: HikariPool-2 - Thread starvation or clock leap detected (housekeeper delta=2m35s983ms).\n",
      "24/03/04 09:22:17 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 906606 ms exceeds timeout 120000 ms\n",
      "24/03/04 09:22:17 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "24/03/04 09:22:20 WARN HikariPool: HikariPool-2 - Thread starvation or clock leap detected (housekeeper delta=15m30s104ms).\n",
      "24/03/04 09:22:20 WARN HikariPool: HikariPool-1 - Thread starvation or clock leap detected (housekeeper delta=15m30s104ms).\n",
      "24/03/04 09:22:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:22:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:22:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:22:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:22:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:22:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:22:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:22:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:23:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:23:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:23:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:23:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:23:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:23:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:24:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:24:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:24:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:25:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:26:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:26:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:26:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:27:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:27:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:27:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:28:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:28:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:28:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:28:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:28:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:28:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:29:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:29:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:29:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:29:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:29:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:29:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:30:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:30:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:30:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:30:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:21 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:21 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:31 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:31 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:31:41 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:41 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:51 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:31:51 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:32:01 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:32:01 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "24/03/04 09:32:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:32:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:577)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.40.105:50157\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "24/03/04 09:32:11 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    " df = data[[\n",
    "    \"meta_レースキー\",\n",
    "    \"meta_着順\",\n",
    "    \"num_一走前着順\",\n",
    "    \"num_二走前着順\",\n",
    "    \"num_三走前着順\",\n",
    "    \"num_トップ3完走\",\n",
    "    \"num_レース数\",\n",
    "    \"num_頭数\",\n",
    "    \"num_1走前頭数\",\n",
    "    \"num_2走前頭数\",\n",
    "    \"num_3走前頭数\",\n",
    "]].copy()\n",
    "\n",
    "df = df.assign(\n",
    "   Current_Place_Norm=(df[\"meta_着順\"] - 1) / (df[\"num_頭数\"] - 1),\n",
    "   Last1_Place_Norm=(df[\"num_一走前着順\"] - 1) / (df[\"num_1走前頭数\"] - 1),\n",
    "   Last2_Place_Norm=(df[\"num_二走前着順\"] - 1) / (df[\"num_2走前頭数\"] - 1),\n",
    "   Last3_Place_Norm=(df[\"num_三走前着順\"] - 1) / (df[\"num_3走前頭数\"] - 1),\n",
    ")\n",
    "\n",
    "# weights = {\"num_一走前着順\": 0.30205828, \"num_二走前着順\": 0.16639774, \"num_三走前着順\": 0.12557666}\n",
    "weights = {\"num_一走前着順\": 0.2927557, \"num_二走前着順\": 0.14651419, \"num_三走前着順\": 0.10043724}\n",
    "print(f\"Weights (determined with linear regression): {weights}\")\n",
    "\n",
    "\n",
    "def calculate_placed(score):\n",
    "    return 1 if score <= 3 else 0\n",
    "\n",
    "\n",
    "for race in weights.keys():\n",
    "    df[f\"{race}_placed\"] = df[race].apply(calculate_placed)\n",
    "\n",
    "df[\"Weighted Score\"] = sum(df[f\"{race}_placed\"] * weight for race, weight in weights.items())\n",
    "\n",
    "df[\"Weighted Score 2\"] = 1 - sum((\n",
    "   df[\"Last1_Place_Norm\"] * weights[\"num_一走前着順\"],\n",
    "    df[\"Last2_Place_Norm\"] * weights[\"num_二走前着順\"],\n",
    "    df[\"Last3_Place_Norm\"] * weights[\"num_三走前着順\"],\n",
    "))\n",
    "\n",
    "df[\"Placed in Current Race\"] = df[\"meta_着順\"] <= 3\n",
    "df[\"Placed 1 race ago\"] = df[\"num_一走前着順\"] <= 3\n",
    "df[\"Placed 2 races ago\"] = df[\"num_二走前着順\"] <= 3\n",
    "df[\"Placed 3 races ago\"] = df[\"num_三走前着順\"] <= 3\n",
    "\n",
    "# Group by the \"placed\" status in past races and calculate the percentage of placing in the current race\n",
    "grouped = df.groupby(\n",
    "    [\"Placed 3 races ago\", \"Placed 2 races ago\", \"Placed 1 race ago\"]\n",
    ")\n",
    "\n",
    "# Calculate the percentage for each group\n",
    "result = grouped[[\"Placed in Current Race\", \"Weighted Score\", \"Weighted Score 2\"]].mean() * 100\n",
    "result = result.reset_index()\n",
    "\n",
    "grouped[[\"Placed in Current Race\", \"Weighted Score\", \"Weighted Score 2\"]].mean().plot(\n",
    "    kind=\"bar\", figsize=(15, 3), rot=0\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weighted Score</th>\n",
       "      <th>Placed in Current Race</th>\n",
       "      <th>Weighted Score 2</th>\n",
       "      <th>Current_Percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weighted Score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259174</td>\n",
       "      <td>0.666663</td>\n",
       "      <td>-0.293687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Placed in Current Race</th>\n",
       "      <td>0.259174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274771</td>\n",
       "      <td>-0.692412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted Score 2</th>\n",
       "      <td>0.666663</td>\n",
       "      <td>0.274771</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.312478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Current_Percentile</th>\n",
       "      <td>-0.293687</td>\n",
       "      <td>-0.692412</td>\n",
       "      <td>-0.312478</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Weighted Score  Placed in Current Race  \\\n",
       "Weighted Score                1.000000                0.259174   \n",
       "Placed in Current Race        0.259174                1.000000   \n",
       "Weighted Score 2              0.666663                0.274771   \n",
       "Current_Percentile           -0.293687               -0.692412   \n",
       "\n",
       "                        Weighted Score 2  Current_Percentile  \n",
       "Weighted Score                  0.666663           -0.293687  \n",
       "Placed in Current Race          0.274771           -0.692412  \n",
       "Weighted Score 2                1.000000           -0.312478  \n",
       "Current_Percentile             -0.312478            1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Weighted Score\", \"Placed in Current Race\", \"Weighted Score 2\"]].assign(\n",
    "    Current_Percentile=df.groupby(\"meta_レースキー\")[\"meta_着順\"].transform(\n",
    "        lambda x: x.rank(pct=True)\n",
    "    )\n",
    ").corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Linear Regression to see if we can optimize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weights for Percentile Ranks: [0.2927557  0.14651419 0.10043724]\n"
     ]
    }
   ],
   "source": [
    "df = data[['meta_レースキー', 'meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順',\n",
    "\"num_頭数\",\n",
    "\"num_1走前頭数\",\n",
    "\"num_2走前頭数\",\n",
    "\"num_3走前頭数\",\n",
    "]].copy().rename(\n",
    "    columns={\n",
    "        \"meta_レースキー\": \"RaceID\",  # Assuming this is the unique identifier for\n",
    "        'meta_着順': 'Current_Place',\n",
    "        'num_一走前着順': 'Last1_Place',\n",
    "        'num_二走前着順': 'Last2_Place',\n",
    "        'num_三走前着順': 'Last3_Place',\n",
    "    }\n",
    ")\n",
    "\n",
    "# df['Current_Percentile'] = df.groupby('RaceID')['Current_Place'].transform(lambda x: x.rank(pct=True))\n",
    "# df['Last1_Percentile'] = df.groupby('RaceID')['Last1_Place'].transform(lambda x: x.rank(pct=True))\n",
    "# df['Last2_Percentile'] = df.groupby('RaceID')['Last2_Place'].transform(lambda x: x.rank(pct=True))\n",
    "# df['Last3_Percentile'] = df.groupby('RaceID')['Last3_Place'].transform(lambda x: x.rank(pct=True))\n",
    "\n",
    "df = df.assign(\n",
    "   Current_Place_Norm=(df[\"Current_Place\"] - 1) / (df[\"num_頭数\"] - 1),\n",
    "   Last1_Place_Norm=(df[\"Last1_Place\"] - 1) / (df[\"num_1走前頭数\"] - 1),\n",
    "   Last2_Place_Norm=(df[\"Last2_Place\"] - 1) / (df[\"num_2走前頭数\"] - 1),\n",
    "   Last3_Place_Norm=(df[\"Last3_Place\"] - 1) / (df[\"num_3走前頭数\"] - 1),\n",
    ")\n",
    "\n",
    "# Assuming 'df' has been updated to include 'Last*_Percentile' columns\n",
    "X = df[['Last1_Place_Norm', 'Last2_Place_Norm', 'Last3_Place_Norm']]\n",
    "y = df['Current_Place_Norm']  # Assuming you've also calculated the percentile rank for the current race\n",
    "\n",
    "# Initialize and fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Retrieve the coefficients (weights)\n",
    "optimal_weights = model.coef_\n",
    "\n",
    "print(\"Optimal Weights for Percentile Ranks:\", optimal_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: Horses that placed well and have rested for fewer days are more likely to place well in the next race.\n",
    "\n",
    "* True\n",
    "* For horses that placed well in the previous race, there is a slight upward trend in probability of placing well as the number of days between races decreases.\n",
    "\n",
    "**How to use:**\n",
    "Use the inverse of the number of rest days during machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/ngsbv_gj3px52qmhqchv10j00000gn/T/ipykernel_82856/1968144509.py:11: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  place_well_percentage = df.groupby('num_休養日数')['Placed_Well'].mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data[['meta_レースキー', 'num_入厩何日前', 'num_休養日数', 'meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順']].copy()\n",
    "\n",
    "df = df[df[\"num_一走前着順\"] <= 3]\n",
    "df['num_休養日数'] = pd.cut(df['num_休養日数'], bins=[i for i  in range(0, 365 * 2, 7)], right=False)\n",
    "df['num_休養日数'] = df['num_休養日数'].apply(lambda x: int(x.right))\n",
    "\n",
    "# Calculate a binary indicator for placing well (1 if placed in top 3, else 0)\n",
    "df['Placed_Well'] = (df['meta_着順'] <= 3).astype(int)\n",
    "\n",
    "# Group by rest days and calculate the percentage of placing well\n",
    "place_well_percentage = df.groupby('num_休養日数')['Placed_Well'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.lineplot(data=place_well_percentage, x='num_休養日数', y='Placed_Well')\n",
    "sns.regplot(data=place_well_percentage, x='num_休養日数', y='Placed_Well', order=1, ci=None, scatter=False)\n",
    "plt.title('Percentage of Horses That Placed Well by Rest Days')\n",
    "plt.xlabel('Rest Days')\n",
    "plt.ylabel('Percentage of Horses That Placed Well')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85    117347\n",
      "           1       0.39      0.20      0.27     33114\n",
      "\n",
      "    accuracy                           0.75    150461\n",
      "   macro avg       0.60      0.56      0.56    150461\n",
      "weighted avg       0.71      0.75      0.72    150461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "df = data[['meta_レースキー', 'num_入厩何日前', 'num_休養日数', 'meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順']].copy()\n",
    "\n",
    "df['Placed_Well'] = (df['meta_着順'] <= 3).astype(int)\n",
    "\n",
    "# Feature Engineering\n",
    "df['Inverse_Rest_Days'] = 1 / df['num_休養日数']\n",
    "df['Rest_Days_Squared'] = df['num_休養日数'] ** 2  # Optional, based on trend observation\n",
    "\n",
    "# Prepare the dataset with the new feature(s)\n",
    "X = df[['num_休養日数', 'Inverse_Rest_Days', 'Rest_Days_Squared', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順']]\n",
    "y = df['Placed_Well']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=random_state)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08733157, 0.08749546, 0.08654568, 0.276003  , 0.22950667,\n",
       "       0.23311762])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get correlation\n",
    "df = data[['num_入厩何日前', 'num_休養日数', 'meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順']].copy()\n",
    "\n",
    "df['Placed_Well'] = (df['meta_着順'] <= 3).astype(int)\n",
    "\n",
    "# Feature Engineering\n",
    "df['Inverse_Rest_Days'] = 1 / df['num_休養日数']\n",
    "df['Rest_Days_Squared'] = df['num_休養日数'] ** 2  # Optional, based on trend observation\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation = df.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f', linewidths=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: Horses that placed in 2 of the past 3 races but lost once (and there was a good excuse for it) have a higher chance of placing than horses that didn't have an excuse.\n",
    "\n",
    "Possible excuses:\n",
    "* 不利 (>=1)\n",
    "* 休み明け\n",
    "\n",
    "Outcome:\n",
    "* True\n",
    "* Effect more pronounced as 不利 increases\n",
    "\n",
    "```\n",
    "Number of Horses in the Target Group: 9242\n",
    "Percentage of Horses in the Target Group That Placed Well: 40.79%\n",
    "Percentage of Horses Not in the Target Group That Placed Well: 21.84%\n",
    "```\n",
    "\n",
    "**How to use:** Create a flag feature for horses in the target group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[data[\"num_一走前不利\"] > 0][\"num_一走前不利\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(15, 3),\n",
    "    rot=0,\n",
    "    title=\"Number of Horses by Disadvantages in the Last Race\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    106643.000000\n",
       "mean         31.756421\n",
       "std          36.809440\n",
       "min           9.000000\n",
       "25%          21.000000\n",
       "50%          25.000000\n",
       "75%          32.000000\n",
       "max        1423.000000\n",
       "Name: num_入厩何日前, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data[['meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順', 'num_休養日数', \"num_入厩何日前\", \"cat_休養理由分類コード\"]].copy()\n",
    "\n",
    "df[~df[\"cat_休養理由分類コード\"].isna()][\"num_入厩何日前\"].plot.hist(\n",
    "    bins=50, figsize=(15, 3), title=\"Rest Days by Rest Reason\"\n",
    ");\n",
    "\n",
    "df[~df[\"cat_休養理由分類コード\"].isna()][\"num_入厩何日前\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Horses in the Target Group: 9242\n",
      "Percentage of Horses in the Target Group That Placed Well: 40.79%\n",
      "Percentage of Horses Not in the Target Group That Placed Well: 21.84%\n"
     ]
    }
   ],
   "source": [
    "df = data[['meta_着順', 'num_一走前着順', 'num_二走前着順', 'num_三走前着順', 'num_一走前不利', 'num_二走前不利', 'num_三走前不利', 'cat_3走前休養理由分類コード']].copy().rename(\n",
    "    columns={\n",
    "        'num_一走前着順': 'num_1走前着順',\n",
    "        'num_二走前着順': 'num_2走前着順',\n",
    "        'num_三走前着順': 'num_3走前着順',\n",
    "        'num_一走前不利': 'num_1走前不利',\n",
    "        'num_二走前不利': 'num_2走前不利',\n",
    "        'num_三走前不利': 'num_3走前不利',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define placing well as finishing in the top 3\n",
    "df['Placed_Well'] = df['meta_着順'].apply(lambda x: 1 if x <= 3 else 0)\n",
    "\n",
    "# Initialize an 'Excuse' column to False\n",
    "df['Excuse'] = False\n",
    "\n",
    "# Check each of the last three races\n",
    "for i in range(1, 4):\n",
    "    # Identify if the horse had a significant excuse in a race it did not place well\n",
    "    df.loc[(df[f'num_{i}走前着順'] > 3) & (df[f'num_{i}走前不利'] >= 1), 'Excuse'] = True\n",
    "\n",
    "# If cat_3走前休養理由分類コード is in ['01', '02', '03', '04', '05', '06', '07'], and num_3走前着順 > 3, then the horse had a excuse\n",
    "df.loc[(df['cat_3走前休養理由分類コード'].isin([\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\"])) & (df['num_3走前着順'] > 3), 'Excuse'] = True\n",
    "\n",
    "# Now, filter horses that placed in 2 of the past 3 races but had a significant excuse in the race they lost\n",
    "df['Placed_Well_2_of_3'] = (df[['num_1走前着順', 'num_2走前着順', 'num_3走前着順']] <= 3).sum(axis=1) == 2\n",
    "df['Target_Group'] = df['Placed_Well_2_of_3'] & df['Excuse']\n",
    "\n",
    "# You can now analyze the 'Target_Group' to compare their performance against other groups\n",
    "percent_a = df[df['Target_Group']]['Placed_Well'].mean() * 100\n",
    "percent_b = df[~df['Target_Group']]['Placed_Well'].mean() * 100\n",
    "\n",
    "print(f\"Number of Horses in the Target Group: {df['Target_Group'].sum()}\")\n",
    "print(f\"Percentage of Horses in the Target Group That Placed Well: {percent_a:.2f}%\")\n",
    "print(f\"Percentage of Horses Not in the Target Group That Placed Well: {percent_b:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 仮説：同一トラック（芝/ダート）の複勝率が条件戦で55%以上、重賞レースで75%以上を超えていて、10走以上の成績がある馬は、堅実な馬であるため、次のレースでも複勝率が高い。\n",
    "\n",
    "This is hard to calculate. Try doing it in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I give up'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"I give up\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 仮説：近10走の複勝率が8割以上の馬は、的中率が高い。\n",
    "\n",
    "* True, but not only 2337 horses over 20 years have this condition..\n",
    "* Lowering the number of required races from 10 to 5 increases the number of horses to 11,000 and the percentage of horses in the target group that placed actually increases to 48.16%.\n",
    "\n",
    "```\n",
    "Number of Horses in the Target Group: 2337\n",
    "Percentage of Horses in the Target Group That Placed Well: 47.75%\n",
    "Percentage of Horses Not in the Target Group That Placed Well: 22.00%\n",
    "```\n",
    "\n",
    "**How to use:**\n",
    "* Create a flag feature for horses in the target group.\n",
    "* Add a feature for the 複勝率 for the past 10 races (check which is more important through features importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Horses in the Target Group: 11122\n",
      "Percentage of Horses in the Target Group That Placed Well: 48.16%\n",
      "Percentage of Horses Not in the Target Group That Placed Well: 21.68%\n"
     ]
    }
   ],
   "source": [
    "df = data[[\"meta_着順\", \"num_レース数\", \"num_トップ3完走率\"]].copy()\n",
    "\n",
    "group_a = df[(df[\"num_レース数\"] >= 5) & (df[\"num_トップ3完走率\"] >= 0.8)]\n",
    "group_b = df[~df.index.isin(group_a.index)]\n",
    "\n",
    "percent_a = (group_a[\"meta_着順\"] <= 3).sum() / group_a.shape[0]\n",
    "percent_b = (group_b[\"meta_着順\"] <= 3).sum() / group_b.shape[0]\n",
    "\n",
    "print(f\"Number of Horses in the Target Group: {group_a.shape[0]}\")\n",
    "print(f\"Percentage of Horses in the Target Group That Placed Well: {percent_a * 100:.2f}%\")\n",
    "print(f\"Percentage of Horses Not in the Target Group That Placed Well: {percent_b * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = pd.DataFrame(index=data.index)\n",
    "\n",
    "# Meta columns\n",
    "data_[\"レースキー\"] = data[\"meta_レースキー\"]\n",
    "data_[\"発走日時\"] = data[\"meta_発走日時\"]\n",
    "data_[\"馬番\"] = data[\"meta_馬番\"]\n",
    "data_[\"着順\"] = data[\"meta_着順\"]\n",
    "data_[\"複勝的中\"] = data[\"meta_複勝的中\"]\n",
    "data_[\"複勝オッズ\"] = data[\"num_事前複勝オッズ\"]\n",
    "data_[\"複勝払戻金\"] = data[\"meta_複勝払戻金\"]\n",
    "data_[\"血統登録番号\"] = data[\"meta_int_race_horses_血統登録番号\"]\n",
    "\n",
    "\n",
    "# Features\n",
    "def calculate_placed(score):\n",
    "    return 1 if score <= 3 else 0\n",
    "\n",
    "\n",
    "weights = {\n",
    "    \"num_一走前着順\": 0.30205828,\n",
    "    \"num_二走前着順\": 0.16639774,\n",
    "    \"num_三走前着順\": 0.12557666,\n",
    "}\n",
    "for race in weights.keys():\n",
    "    data[f\"{race}_placed\"] = data[race].apply(calculate_placed)\n",
    "\n",
    "\n",
    "data[\"Weighted Score\"] = sum(data[f\"{race}_placed\"] * weight for race, weight in weights.items())\n",
    "\n",
    "# Filtering\n",
    "# data_ = data_[data_[\"発走日時\"].dt.year >= 2003]\n",
    "\n",
    "\n",
    "# fmt: off\n",
    "categories = [\n",
    "    [\"距離\", [1000, 1150, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 3000, 3200, 3400, 3600]],\n",
    "    [\"枠番\", [1, 2, 3, 4, 5, 6, 7, 8]],\n",
    "]\n",
    "category_keys = [category[0] for category in categories] if categories else []\n",
    "category_values = [category[1] for category in categories] if categories else []\n",
    "num_cols = [\n",
    "    \"前走距離差\",\n",
    "    \"年齢\",\n",
    "    \"馬体重増減\",\n",
    "    \"負担重量\",\n",
    "    \"頭数\",\n",
    "    \"情報指数\",\n",
    "    \"騎手指数\",\n",
    "    \"総合情報◎\",\n",
    "    \"競争相手平均総合指数差\",\n",
    "]\n",
    "num_null_cols = [\n",
    "    \"馬体重\",  # 95% of 馬体重 null values are where 異常区分 != 0\n",
    "    \"競争相手平均入厩何日前\"\n",
    "]\n",
    "cat_cols = [\n",
    "    \"トラック種別\"\n",
    "]\n",
    "meta_cols = [\"レースキー\", \"複勝的中\", \"複勝払戻金\"]\n",
    "all_cols = category_keys + num_cols + num_null_cols + cat_cols + meta_cols\n",
    "# fmt: on\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         # fmt: off\n",
    "#         (\"ord\", OrdinalEncoder(categories=category_values), category_keys),\n",
    "#         (\"num\", StandardScaler(), num_cols),\n",
    "#         (\"num_null\", Pipeline(steps=[(\"imputer\", SimpleImputer()), (\"scaler\", StandardScaler())]), num_null_cols),\n",
    "#         (\"cat\", OneHotEncoder(drop=\"if_binary\"), cat_cols),\n",
    "#         (\"meta\", \"passthrough\", meta_cols)\n",
    "#         # fmt: on\n",
    "#     ],\n",
    "#     remainder=\"drop\",\n",
    "# )\n",
    "\n",
    "# pipeline = ImblearnPipeline(\n",
    "#     steps=[\n",
    "#         (\"preprocessor\", preprocessor),\n",
    "#         (\"smote\", SMOTE(random_state=random_state)),\n",
    "#         (\"classifier\", LGBMClassifier(random_state=random_state)),\n",
    "#     ]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
