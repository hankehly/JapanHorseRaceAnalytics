{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis: 上がり3Fが速い馬は成績がいい\n",
    "\n",
    "* Created weighted average 3F time rank feature for past 3 races. No predictive power found.\n",
    "* 重み can be calculated by 1/days_since_last_race+1e6 which is easier to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from JapanHorseRaceAnalytics.utilities.base import get_spark_session, read_hive_table\n",
    "from JapanHorseRaceAnalytics.utilities.structured_logger import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/16 11:53:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"event\": \"Read from parquet /Users/hankehly/Projects/JapanHorseRaceAnalytics/data/sql_tables/features_20240304_v1.snappy.parquet to pandas\", \"level\": \"info\", \"timestamp\": \"2024-03-16T02:53:49.155007Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "{\"event\": \"Original data length: 1217019\", \"level\": \"info\", \"timestamp\": \"2024-03-16T02:53:49.639385Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n",
      "{\"event\": \"Data length after filtering: 808861 (dropped 408158 rows, 33.54%)\", \"level\": \"info\", \"timestamp\": \"2024-03-16T02:53:49.986265Z\", \"logger\": \"JapanHorseRaceAnalytics.utilities.base\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_単勝払戻金</th>\n",
       "      <th>meta_複勝払戻金</th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_馬番</th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_単勝的中</th>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <th>meta_複勝オッズ</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_6走前休養理由分類コード</th>\n",
       "      <th>num_6走前3着タイム差</th>\n",
       "      <th>cat_トラック種別</th>\n",
       "      <th>num_距離</th>\n",
       "      <th>num_過去3走重み付き着順成績</th>\n",
       "      <th>num_入厩何日前逆数</th>\n",
       "      <th>cat_堅実な馬</th>\n",
       "      <th>cat_過去3走中1走訳あり凡走</th>\n",
       "      <th>cat_過去3走中2走好走</th>\n",
       "      <th>cat_過去3走繋がりあり</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>07023401</td>\n",
       "      <td>10</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2002-12-08 10:00:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.290165</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07032804</td>\n",
       "      <td>12</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-06-15 11:25:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.136197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09033503</td>\n",
       "      <td>03</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-07-05 10:55:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.184235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>270</td>\n",
       "      <td>150</td>\n",
       "      <td>10032202</td>\n",
       "      <td>02</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-07-20 10:30:00+09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>3.7</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1700</td>\n",
       "      <td>0.197533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>09034208</td>\n",
       "      <td>12</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-09-14 14:00:00+09:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>1.8</td>\n",
       "      <td>ダート</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.108824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meta_単勝払戻金  meta_複勝払戻金 meta_レースキー meta_馬番 meta_血統登録番号  \\\n",
       "0           0         240   07023401      10    00100184   \n",
       "1           0           0   07032804      12    00100184   \n",
       "2           0           0   09033503      03    00100184   \n",
       "3         270         150   10032202      02    00100184   \n",
       "4           0           0   09034208      12    00100184   \n",
       "\n",
       "                   meta_発走日時  meta_単勝的中  meta_複勝的中  meta_複勝オッズ  meta_着順  ...  \\\n",
       "0  2002-12-08 10:00:00+09:00          0          1         1.7      2.0  ...   \n",
       "1  2003-06-15 11:25:00+09:00          0          0         2.6      8.0  ...   \n",
       "2  2003-07-05 10:55:00+09:00          0          0         1.5      7.0  ...   \n",
       "3  2003-07-20 10:30:00+09:00          1          1         1.2      1.0  ...   \n",
       "4  2003-09-14 14:00:00+09:00          0          0         7.8     12.0  ...   \n",
       "\n",
       "   cat_6走前休養理由分類コード  num_6走前3着タイム差 cat_トラック種別 num_距離  num_過去3走重み付き着順成績  \\\n",
       "0              None            NaN        ダート   1700          0.290165   \n",
       "1              None            NaN        ダート   1700          0.136197   \n",
       "2              None            NaN        ダート   1800          0.184235   \n",
       "3              None            3.7        ダート   1700          0.197533   \n",
       "4              None            1.8        ダート   1800          0.108824   \n",
       "\n",
       "   num_入厩何日前逆数 cat_堅実な馬  cat_過去3走中1走訳あり凡走  cat_過去3走中2走好走  cat_過去3走繋がりあり  \n",
       "0          1.0    False             False          False          False  \n",
       "1          1.0    False             False          False          False  \n",
       "2          1.0    False             False          False          False  \n",
       "3          1.0    False             False          False          False  \n",
       "4          1.0    False             False          False          False  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_hive_table(\n",
    "    table_name=\"features_20240304_v1\",\n",
    "    schema=\"jhra_curated\",\n",
    "    spark_session=spark,\n",
    "    # use_cache=False,\n",
    "    parse_dates=[\"meta_発走日時\"],\n",
    ")\n",
    "\n",
    "rows_before = data.shape[0]\n",
    "logger.info(f\"Original data length: {rows_before}\")\n",
    "\n",
    "# Drop from data where cat_トラック種別 == \"障害\"\n",
    "# Keep only horses that have 3 races\n",
    "# Keep only data from 2000 onwards\n",
    "data = data[\n",
    "    (data[\"cat_トラック種別\"] != \"障害\")\n",
    "    & (data[\"meta_異常区分\"] == \"0\")\n",
    "    & (data[\"num_1走前着順\"].notnull())\n",
    "    & (data[\"num_2走前着順\"].notnull())\n",
    "    & (data[\"num_3走前着順\"].notnull())\n",
    "    & (data[\"meta_発走日時\"] >= \"2000-01-01\")\n",
    "]\n",
    "\n",
    "rows_after = data.shape[0]\n",
    "logger.info(\n",
    "    f\"Data length after filtering: {rows_after} (dropped {rows_before - rows_after} rows, {100 * (rows_before - rows_after) / rows_before:.2f}%)\"\n",
    ")\n",
    "\n",
    "# Interpolate missing values for num_馬体重 (20 instances from 1999 ~ 2017)\n",
    "data[\"num_馬体重\"] = (\n",
    "    data.sort_values(\"meta_発走日時\")\n",
    "    .groupby(\"meta_血統登録番号\")[\"num_馬体重\"]\n",
    "    .transform(lambda x: x.interpolate(method=\"linear\", limit_direction=\"both\"))\n",
    ")\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71593,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"meta_レースキー\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_後３Ｆタイム</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07023401</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2002-12-08 10:00:00+09:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07032804</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-06-15 11:25:00+09:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09033503</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-07-05 10:55:00+09:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10032202</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-07-20 10:30:00+09:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09034208</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2003-09-14 14:00:00+09:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_レースキー meta_血統登録番号                  meta_発走日時  meta_着順 meta_後３Ｆタイム\n",
       "0   07023401    00100184  2002-12-08 10:00:00+09:00      2.0        39.9\n",
       "1   07032804    00100184  2003-06-15 11:25:00+09:00      8.0        38.7\n",
       "2   09033503    00100184  2003-07-05 10:55:00+09:00      7.0        39.8\n",
       "3   10032202    00100184  2003-07-20 10:30:00+09:00      1.0        40.5\n",
       "4   09034208    00100184  2003-09-14 14:00:00+09:00     12.0        43.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"meta_レースキー\", \"meta_血統登録番号\", \"meta_発走日時\", \"meta_着順\", \"meta_後３Ｆタイム\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"meta_レースキー\", \"meta_血統登録番号\", \"meta_発走日時\", \"meta_着順\", \"meta_後３Ｆタイム\"]].to_csv(\"data.csv.gz\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(meta_着順        0\n",
       " meta_後３Ｆタイム    3\n",
       " dtype: int64,\n",
       " 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "# Convert 'meta_着順' to a numeric type, forcing errors to NaN (e.g., non-numeric values become NaN)\n",
    "data['meta_着順'] = pd.to_numeric(data['meta_着順'], errors='coerce')\n",
    "data['meta_後３Ｆタイム'] = pd.to_numeric(data['meta_後３Ｆタイム'], errors='coerce')\n",
    "\n",
    "# Check for missing values in 'meta_着順' and 'meta_後３Ｆタイム'\n",
    "missing_values = data[['meta_着順', 'meta_後３Ｆタイム']].isnull().sum()\n",
    "\n",
    "# Dropping rows where 'meta_着順' or 'meta_後３Ｆタイム' is missing\n",
    "cleaned_data = data.dropna(subset=['meta_着順', 'meta_後３Ｆタイム'])\n",
    "\n",
    "# Check how many rows were dropped\n",
    "rows_dropped = data.shape[0] - cleaned_data.shape[0]\n",
    "\n",
    "missing_values, rows_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/ngsbv_gj3px52qmhqchv10j00000gn/T/ipykernel_74901/3703215963.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_data['3F_time_rank'] = cleaned_data.groupby('meta_レースキー')['meta_後３Ｆタイム'].rank() / cleaned_data.groupby('meta_レースキー')['meta_後３Ｆタイム'].transform('count')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_後３Ｆタイム</th>\n",
       "      <th>3F_time_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07023401</td>\n",
       "      <td>00100184</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>07032804</td>\n",
       "      <td>00100184</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09033503</td>\n",
       "      <td>00100184</td>\n",
       "      <td>7.0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10032202</td>\n",
       "      <td>00100184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09034208</td>\n",
       "      <td>00100184</td>\n",
       "      <td>12.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meta_レースキー meta_血統登録番号  meta_着順  meta_後３Ｆタイム  3F_time_rank\n",
       "0   07023401    00100184      2.0         39.9      0.444444\n",
       "1   07032804    00100184      8.0         38.7      0.650000\n",
       "2   09033503    00100184      7.0         39.8      0.750000\n",
       "3   10032202    00100184      1.0         40.5      0.111111\n",
       "4   09034208    00100184     12.0         43.5      1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a rank column for the last 3F times within each race\n",
    "cleaned_data['3F_time_rank'] = cleaned_data.groupby('meta_レースキー')['meta_後３Ｆタイム'].rank() / cleaned_data.groupby('meta_レースキー')['meta_後３Ｆタイム'].transform('count')\n",
    "\n",
    "# Displaying the adjusted dataframe to verify the ranking\n",
    "cleaned_data[['meta_レースキー', 'meta_血統登録番号', 'meta_着順', 'meta_後３Ｆタイム', '3F_time_rank']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>3F_time_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta_着順</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3F_time_rank</th>\n",
       "      <td>0.665796</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               meta_着順  3F_time_rank\n",
       "meta_着順       1.000000      0.665796\n",
       "3F_time_rank  0.665796      1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Spearman correlation between the 3F time rank and the final positions\n",
    "correlation = cleaned_data[['meta_着順', '3F_time_rank']].corr(method='spearman')\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1p/ngsbv_gj3px52qmhqchv10j00000gn/T/ipykernel_74901/751873625.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_data['meta_発走日時'] = pd.to_datetime(cleaned_data['meta_発走日時'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_後３Ｆタイム</th>\n",
       "      <th>next_race_time</th>\n",
       "      <th>next_final_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161249</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2003-04-06 15:10:00+09:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>2003-04-12 15:40:00+09:00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161250</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2003-04-12 15:40:00+09:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>2003-05-11 15:40:00+09:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161251</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2003-05-11 15:40:00+09:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2003-11-30 14:40:00+09:00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161252</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2003-11-30 14:40:00+09:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>2004-01-05 15:45:00+09:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161253</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2004-01-05 15:45:00+09:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>2004-10-30 15:45:00+09:00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       meta_血統登録番号                 meta_発走日時  meta_着順  meta_後３Ｆタイム  \\\n",
       "161249    00100002 2003-04-06 15:10:00+09:00      5.0         35.8   \n",
       "161250    00100002 2003-04-12 15:40:00+09:00      1.0         34.6   \n",
       "161251    00100002 2003-05-11 15:40:00+09:00      2.0         34.7   \n",
       "161252    00100002 2003-11-30 14:40:00+09:00      2.0         37.3   \n",
       "161253    00100002 2004-01-05 15:45:00+09:00      5.0         35.4   \n",
       "\n",
       "                  next_race_time  next_final_position  \n",
       "161249 2003-04-12 15:40:00+09:00                  1.0  \n",
       "161250 2003-05-11 15:40:00+09:00                  2.0  \n",
       "161251 2003-11-30 14:40:00+09:00                  2.0  \n",
       "161252 2004-01-05 15:45:00+09:00                  5.0  \n",
       "161253 2004-10-30 15:45:00+09:00                  8.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure the race time is in datetime format for correct sorting\n",
    "cleaned_data['meta_発走日時'] = pd.to_datetime(cleaned_data['meta_発走日時'])\n",
    "\n",
    "# Sort the data by Horse ID and Race Time to track performance over time\n",
    "sorted_data = cleaned_data.sort_values(by=['meta_血統登録番号', 'meta_発走日時'])\n",
    "\n",
    "# Add columns to identify the next race for each horse and the change in final position\n",
    "sorted_data['next_race_time'] = sorted_data.groupby('meta_血統登録番号')['meta_発走日時'].shift(-1)\n",
    "sorted_data['next_final_position'] = sorted_data.groupby('meta_血統登録番号')['meta_着順'].shift(-1)\n",
    "\n",
    "# For analysis, we only need rows where both the current and next races are known\n",
    "analysis_data = sorted_data.dropna(subset=['next_race_time', 'next_final_position'])\n",
    "\n",
    "# Display the first few rows to verify the new structure\n",
    "analysis_data[['meta_血統登録番号', 'meta_発走日時', 'meta_着順', 'meta_後３Ｆタイム', 'next_race_time', 'next_final_position']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Identify the top quartile of 3F time performers within each race\n",
    "# # Quartile calculation within each race\n",
    "# analysis_data['3F_time_quartile'] = analysis_data.groupby('meta_レースキー')['meta_後３Ｆタイム'].transform(\n",
    "#     lambda x: pd.qcut(x, 4, labels=False, duplicates='drop')\n",
    "# )\n",
    "\n",
    "# # For simplification, consider 'fast' as being in the top quartile (0th quartile after labels=False)\n",
    "# # Analyze the change in final position for these 'fast' horses\n",
    "# # A negative change means improvement (a lower final position number is better)\n",
    "# analysis_data['position_change'] = analysis_data['meta_着順'] - analysis_data['next_final_position']\n",
    "\n",
    "# # Repeating the necessary step due to the execution environment issue\n",
    "# # Calculate the average change in position for fast horses to see if there's a general improvement\n",
    "\n",
    "# # Filter the analysis_data for fast horses in the top quartile within their race for the 3F time\n",
    "# fast_horses_data = analysis_data[analysis_data['3F_time_quartile'] == 0]\n",
    "\n",
    "# # Calculate the average change in position for these fast horses (next race position - current race position)\n",
    "# average_position_change_fast_horses = fast_horses_data['position_change'].mean()\n",
    "\n",
    "# This was something like -2.3, which means that the average change in position for fast horses is -2.3\n",
    "# average_position_change_fast_horses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_単勝払戻金</th>\n",
       "      <th>meta_複勝払戻金</th>\n",
       "      <th>meta_レースキー</th>\n",
       "      <th>meta_馬番</th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>meta_単勝的中</th>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <th>meta_複勝オッズ</th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>...</th>\n",
       "      <th>num_距離</th>\n",
       "      <th>num_過去3走重み付き着順成績</th>\n",
       "      <th>num_入厩何日前逆数</th>\n",
       "      <th>cat_堅実な馬</th>\n",
       "      <th>cat_過去3走中1走訳あり凡走</th>\n",
       "      <th>cat_過去3走中2走好走</th>\n",
       "      <th>cat_過去3走繋がりあり</th>\n",
       "      <th>3F_time_rank</th>\n",
       "      <th>next_race_time</th>\n",
       "      <th>next_final_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [meta_単勝払戻金, meta_複勝払戻金, meta_レースキー, meta_馬番, meta_血統登録番号, meta_発走日時, meta_単勝的中, meta_複勝的中, meta_複勝オッズ, meta_着順, meta_タイム, meta_不利, meta_異常区分, meta_後３Ｆタイム, meta_3着タイム差, meta_3着タイム, cat_場コード, num_入厩何日前, num_頭数, num_年齢, cat_性別, num_ローテーション, num_負担重量, num_馬体重, num_平均馬体重差, num_レース数, num_複勝回数, num_複勝率, num_1走前距離, num_1走前不利, num_1走前経過日数, num_1走前頭数, num_1走前着順, num_1走前後続馬1タイム差, num_1走前後続馬2タイム差, num_1走前後続馬3タイム差, num_1走前後続馬4タイム差, num_1走前後続馬5タイム差, cat_1走前休養理由分類コード, num_1走前3着タイム差, num_2走前距離, num_2走前不利, num_2走前経過日数, num_2走前頭数, num_2走前着順, num_2走前後続馬1タイム差, num_2走前後続馬2タイム差, num_2走前後続馬3タイム差, num_2走前後続馬4タイム差, num_2走前後続馬5タイム差, cat_2走前休養理由分類コード, num_2走前3着タイム差, num_3走前距離, num_3走前不利, num_3走前経過日数, num_3走前頭数, num_3走前着順, num_3走前後続馬1タイム差, num_3走前後続馬2タイム差, num_3走前後続馬3タイム差, num_3走前後続馬4タイム差, num_3走前後続馬5タイム差, cat_3走前休養理由分類コード, num_3走前3着タイム差, num_4走前距離, num_4走前不利, num_4走前経過日数, num_4走前頭数, num_4走前着順, num_4走前後続馬1タイム差, num_4走前後続馬2タイム差, num_4走前後続馬3タイム差, num_4走前後続馬4タイム差, num_4走前後続馬5タイム差, cat_4走前休養理由分類コード, num_4走前3着タイム差, num_5走前距離, num_5走前不利, num_5走前経過日数, num_5走前頭数, num_5走前着順, num_5走前後続馬1タイム差, num_5走前後続馬2タイム差, num_5走前後続馬3タイム差, num_5走前後続馬4タイム差, num_5走前後続馬5タイム差, cat_5走前休養理由分類コード, num_5走前3着タイム差, num_6走前距離, num_6走前不利, num_6走前経過日数, num_6走前頭数, num_6走前着順, num_6走前後続馬1タイム差, num_6走前後続馬2タイム差, num_6走前後続馬3タイム差, num_6走前後続馬4タイム差, num_6走前後続馬5タイム差, cat_6走前休養理由分類コード, num_6走前3着タイム差, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 111 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data[analysis_data[\"meta_レースキー\"] == \"10023205\"].sort_values(\"meta_着順\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_血統登録番号</th>\n",
       "      <th>meta_発走日時</th>\n",
       "      <th>weighted_avg_3F_time_rank</th>\n",
       "      <th>weighted_avg_position_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161253</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2004-01-05 15:45:00+09:00</td>\n",
       "      <td>0.169534</td>\n",
       "      <td>-3.067729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161254</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2004-10-30 15:45:00+09:00</td>\n",
       "      <td>0.283744</td>\n",
       "      <td>1.753564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161255</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2004-11-27 15:25:00+09:00</td>\n",
       "      <td>0.453480</td>\n",
       "      <td>2.590042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161256</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2004-12-11 15:35:00+09:00</td>\n",
       "      <td>0.377156</td>\n",
       "      <td>-0.740469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161257</th>\n",
       "      <td>00100002</td>\n",
       "      <td>2005-01-15 15:35:00+09:00</td>\n",
       "      <td>0.361040</td>\n",
       "      <td>2.030270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       meta_血統登録番号                 meta_発走日時  weighted_avg_3F_time_rank  \\\n",
       "161253    00100002 2004-01-05 15:45:00+09:00                   0.169534   \n",
       "161254    00100002 2004-10-30 15:45:00+09:00                   0.283744   \n",
       "161255    00100002 2004-11-27 15:25:00+09:00                   0.453480   \n",
       "161256    00100002 2004-12-11 15:35:00+09:00                   0.377156   \n",
       "161257    00100002 2005-01-15 15:35:00+09:00                   0.361040   \n",
       "\n",
       "        weighted_avg_position_change  \n",
       "161253                     -3.067729  \n",
       "161254                      1.753564  \n",
       "161255                      2.590042  \n",
       "161256                     -0.740469  \n",
       "161257                      2.030270  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data = cleaned_data.sort_values(by=['meta_血統登録番号', 'meta_発走日時'])\n",
    "\n",
    "# Adjusting the calculation of inverse weights to avoid division by zero without introducing lookahead\n",
    "# The subtraction by the min might not be necessary unless you're trying to normalize the weights\n",
    "sorted_data['inverse_days_weight'] = 1 / sorted_data['num_1走前経過日数']\n",
    "\n",
    "def calculate_weighted_features(group):\n",
    "    # Calculate rolling sums of weights for the past 3 races\n",
    "    roll_sum_weights = group['inverse_days_weight'].rolling(window=3).sum()\n",
    "    \n",
    "    # Weighted 3F time rank using past 3 races data\n",
    "    weighted_3F_time_rank = (group['3F_time_rank'] * group['inverse_days_weight']).rolling(window=3).sum() / roll_sum_weights\n",
    "    \n",
    "    # Calculate position changes based on past data only\n",
    "    # Removing shift(-1) to avoid lookahead\n",
    "    position_changes = group['meta_着順'].diff()  # This now correctly calculates the change based on previous race\n",
    "    weighted_position_change = (position_changes * group['inverse_days_weight']).rolling(window=3).sum() / roll_sum_weights\n",
    "    \n",
    "    # Shift the entire calculation by 1 to use it for predictions without including the current race's data\n",
    "    return pd.DataFrame({\n",
    "        'weighted_avg_3F_time_rank': weighted_3F_time_rank.shift(1),  \n",
    "        'weighted_avg_position_change': weighted_position_change.shift(1)  \n",
    "    })\n",
    "\n",
    "# Apply the function to each group\n",
    "weighted_features = sorted_data.groupby('meta_血統登録番号').apply(calculate_weighted_features).reset_index(level=0, drop=True)\n",
    "\n",
    "# Join the calculated weighted features back to the sorted_data DataFrame\n",
    "sorted_data = sorted_data.join(weighted_features)\n",
    "\n",
    "# Drop NaN values resulting from rolling calculations and shifting\n",
    "sorted_data.dropna(subset=['weighted_avg_3F_time_rank', 'weighted_avg_position_change'], inplace=True)\n",
    "\n",
    "# Display to verify the new columns\n",
    "sorted_data[['meta_血統登録番号', 'meta_発走日時', 'weighted_avg_3F_time_rank', 'weighted_avg_position_change']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_着順</th>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <th>weighted_avg_3F_time_rank</th>\n",
       "      <th>weighted_avg_position_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meta_着順</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.716781</td>\n",
       "      <td>0.230324</td>\n",
       "      <td>0.073013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta_複勝的中</th>\n",
       "      <td>-0.716781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148397</td>\n",
       "      <td>-0.048977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_avg_3F_time_rank</th>\n",
       "      <td>0.230324</td>\n",
       "      <td>-0.148397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_avg_position_change</th>\n",
       "      <td>0.073013</td>\n",
       "      <td>-0.048977</td>\n",
       "      <td>0.262930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               meta_着順  meta_複勝的中  weighted_avg_3F_time_rank  \\\n",
       "meta_着順                       1.000000  -0.716781                   0.230324   \n",
       "meta_複勝的中                    -0.716781   1.000000                  -0.148397   \n",
       "weighted_avg_3F_time_rank     0.230324  -0.148397                   1.000000   \n",
       "weighted_avg_position_change  0.073013  -0.048977                   0.262930   \n",
       "\n",
       "                              weighted_avg_position_change  \n",
       "meta_着順                                           0.073013  \n",
       "meta_複勝的中                                        -0.048977  \n",
       "weighted_avg_3F_time_rank                         0.262930  \n",
       "weighted_avg_position_change                      1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Spearman correlation between the 3F time rank and the final positions\n",
    "sorted_data[['meta_着順', \"meta_複勝的中\", 'weighted_avg_3F_time_rank', \"weighted_avg_position_change\"]].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (426862, 112)\n",
      "X_test: (106716, 112)\n",
      "y_train: (426862,)\n",
      "y_test: (106716,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = sorted_data.copy()\n",
    "\n",
    "X = df\n",
    "y = df[\"meta_複勝的中\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tempfile\n",
    "import re\n",
    "import japanize_matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import warnings\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImblearnPipeline\n",
    "from hyperopt import STATUS_OK\n",
    "from JapanHorseRaceAnalytics.utilities.metrics import (\n",
    "    calculate_payout_rate,\n",
    "    kelly_criterion\n",
    ")\n",
    "\n",
    "from JapanHorseRaceAnalytics.utilities.plot import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_feature_importances,\n",
    "    plot_shap_interaction_values,\n",
    "    plot_correlation_matrix,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def create_objective_fn(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series,\n",
    "    payouts: pd.DataFrame,\n",
    "    payout_column_name: str,\n",
    "    mlflow_experiment_name: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    payouts should have the same index as *_test and have the following columns:\n",
    "    * 発走日時\n",
    "    * odds\n",
    "    * payout\n",
    "    \"\"\"\n",
    "\n",
    "    def train(params):\n",
    "        mlflow.set_experiment(experiment_name=mlflow_experiment_name)\n",
    "        with mlflow.start_run():\n",
    "            ########################################################################################\n",
    "            # decay_rate = params[\"features__decay_rate\"]\n",
    "\n",
    "            for df in [X_train, X_test]:\n",
    "                # 1. Weighted average position\n",
    "                df[\"num_1走前標準化着順\"] = (df[\"num_1走前着順\"] - 1) / (df[\"num_1走前頭数\"] - 1)\n",
    "                df[\"num_2走前標準化着順\"] = (df[\"num_2走前着順\"] - 1) / (df[\"num_2走前頭数\"] - 1)\n",
    "                df[\"num_3走前標準化着順\"] = (df[\"num_3走前着順\"] - 1) / (df[\"num_3走前頭数\"] - 1)\n",
    "                # We want our factor (num_1走前経過日数) to start from 0\n",
    "                # so subtract the minimum value for \"days since last race\" across all horses\n",
    "                # Add a small number to avoid division by zero\n",
    "                df[\"num_1走前重み\"] = 1 / (df[\"num_1走前経過日数\"] - df[\"num_1走前経過日数\"].min() + 1e-6)\n",
    "                df[\"num_2走前重み\"] = 1 / (df[\"num_2走前経過日数\"] - df[\"num_1走前経過日数\"].min() + 1e-6)\n",
    "                df[\"num_3走前重み\"] = 1 / (df[\"num_3走前経過日数\"] - df[\"num_1走前経過日数\"].min() + 1e-6)\n",
    "                # df[\"num_2走前重み\"] = np.exp(-decay_rate * (df[\"num_2走前経過日数\"] - df[\"num_1走前経過日数\"].min()))\n",
    "                # df[\"num_3走前重み\"] = np.exp(-decay_rate * (df[\"num_3走前経過日数\"] - df[\"num_1走前経過日数\"].min()))\n",
    "                # Calculate weighted average of the feature\n",
    "                # weighted_feature_values = np.average([value for _, value in races], weights=weights)\n",
    "                df[\"num_過去3走重み付き標準化着順\"] = (\n",
    "                    (df[\"num_1走前標準化着順\"] * df[\"num_1走前重み\"])\n",
    "                    + (df[\"num_2走前標準化着順\"] * df[\"num_2走前重み\"])\n",
    "                    + (df[\"num_3走前標準化着順\"] * df[\"num_3走前重み\"])\n",
    "                ) / (df[\"num_1走前重み\"] + df[\"num_2走前重み\"] + df[\"num_3走前重み\"])\n",
    "\n",
    "                # 2. Weighted average time difference between the horse and the 3 horses behind it\n",
    "                df[\"num_1走前後続馬平均タイム差\"] = (\n",
    "                    df[[\"num_1走前後続馬1タイム差\", \"num_1走前後続馬2タイム差\", \"num_1走前後続馬3タイム差\"]]\n",
    "                    .mean(axis=1)\n",
    "                    .fillna(0)\n",
    "                )\n",
    "                df[\"num_2走前後続馬平均タイム差\"] = (\n",
    "                    df[[\"num_2走前後続馬1タイム差\", \"num_2走前後続馬2タイム差\", \"num_2走前後続馬3タイム差\"]]\n",
    "                    .mean(axis=1)\n",
    "                    .fillna(0)\n",
    "                )\n",
    "                df[\"num_3走前後続馬平均タイム差\"] = (\n",
    "                    df[[\"num_3走前後続馬1タイム差\", \"num_3走前後続馬2タイム差\", \"num_3走前後続馬3タイム差\"]]\n",
    "                    .mean(axis=1)\n",
    "                    .fillna(0)\n",
    "                )\n",
    "                df[\"num_過去3走重み付き後続馬平均タイム差\"] = (\n",
    "                    (df[\"num_1走前後続馬平均タイム差\"] * df[\"num_1走前重み\"])\n",
    "                    + (df[\"num_2走前後続馬平均タイム差\"] * df[\"num_2走前重み\"])\n",
    "                    + (df[\"num_3走前後続馬平均タイム差\"] * df[\"num_3走前重み\"])\n",
    "                ) / (df[\"num_1走前重み\"] + df[\"num_2走前重み\"] + df[\"num_3走前重み\"])\n",
    "            ########################################################################################\n",
    "            preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    # (\n",
    "                    #     \"cat\",\n",
    "                    #     OneHotEncoder(drop=\"if_binary\", handle_unknown=\"error\"),\n",
    "                    #     [\"cat_性別\", \"cat_場コード\", \"cat_トラック種別\"],\n",
    "                    # ),\n",
    "                    (\n",
    "                        \"num\",\n",
    "                        StandardScaler(),\n",
    "                        [\n",
    "                            \"num_複勝率\",\n",
    "                            \"num_1走前経過日数\",\n",
    "                            \"num_過去3走重み付き標準化着順\",\n",
    "                            \"num_過去3走重み付き後続馬平均タイム差\",\n",
    "                            \"weighted_avg_3F_time_rank\",\n",
    "                            \"weighted_avg_position_change\",\n",
    "                        ],\n",
    "                    ),\n",
    "                ],\n",
    "                remainder=\"drop\",\n",
    "            )\n",
    "\n",
    "            # Get all keys from params where the key starts with \"smote__\" and remove \"smote__\" from the key\n",
    "            smote_params = {k.split(\"__\")[1]: v for k, v in params.items() if k.startswith(\"smote__\")}\n",
    "\n",
    "            # do the same for classifier\n",
    "            classifier_params = {k.split(\"__\")[1]: v for k, v in params.items() if k.startswith(\"classifier__\")}\n",
    "\n",
    "            model = ImblearnPipeline(\n",
    "                steps=[\n",
    "                    (\"preprocessor\", preprocessor),\n",
    "                    (\"smote\", SMOTE(**smote_params)),\n",
    "                    (\"classifier\", LGBMClassifier(**classifier_params)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            metrics = {\n",
    "                \"loss\": -precision_score(y_test, y_pred),\n",
    "                \"log_loss\": log_loss(y_test, y_proba[:, 1]),\n",
    "                \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "                \"precision\": precision_score(y_test, y_pred),\n",
    "                \"recall\": recall_score(y_test, y_pred),\n",
    "                \"f1\": f1_score(y_test, y_pred),\n",
    "                \"roc_auc\": roc_auc_score(y_test, y_pred),\n",
    "            }\n",
    "\n",
    "            mlflow.log_params(classifier_params)\n",
    "            # mlflow.log_param(\"decay_rate\", decay_rate)\n",
    "            mlflow.log_metrics(metrics)\n",
    "            mlflow.sklearn.log_model(sk_model=model, artifact_path=\"model\")\n",
    "\n",
    "            payout = calculate_payout_rate(\n",
    "                payouts=payouts,\n",
    "                y_test=y_test,\n",
    "                y_proba_true=y_proba[:, 1],\n",
    "                groupby=[\n",
    "                    (\"all\", None),\n",
    "                    (\"month\", payouts[\"発走日時\"].dt.month),\n",
    "                    (\"season\", payouts[\"発走日時\"].dt.month % 12 // 3),\n",
    "                    (\"year\", payouts[\"発走日時\"].dt.year),\n",
    "                ],\n",
    "                payout_column_name=payout_column_name,\n",
    "            )\n",
    "\n",
    "            # Save payout rates as csv\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"payout_rate_\", suffix=\".csv\") as f:\n",
    "                payout.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Log payout rates as metrics\n",
    "            payout_metrics = {}\n",
    "            for group_name, group in payout.groupby(\"group\"):\n",
    "                for i, row in group.iterrows():\n",
    "                    key = re.sub(r\"\\W\", \"_\", f\"payout_rate_{group_name}_{row['part']}\")\n",
    "                    payout_metrics[key] = row[\"payout_rate\"]\n",
    "            mlflow.log_metrics(payout_metrics)\n",
    "\n",
    "            # Suppress UserWarning messages from matplotlib\n",
    "            warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "            # Confusion Matrix\n",
    "            fig, axes = plot_confusion_matrix(y_test, y_pred)\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"confusion_matrix_\", suffix=\".png\"\n",
    "            ) as f:\n",
    "                fig.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # ROC Curve\n",
    "            fig, ax = plot_roc_curve(y_test, y_proba[:, 1])\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"roc_curve_\", suffix=\".png\") as f:\n",
    "                fig.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Feature Importances Plot\n",
    "            fig, ax = plot_feature_importances(\n",
    "                preprocessor.get_feature_names_out(),\n",
    "                model.named_steps[\"classifier\"].feature_importances_,\n",
    "                top_n=50,\n",
    "            )\n",
    "            with tempfile.NamedTemporaryFile(\n",
    "                prefix=\"feature_importance_\", suffix=\".png\"\n",
    "            ) as f:\n",
    "                fig.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Feature Importances Data\n",
    "            feature_importances = zip(\n",
    "                preprocessor.get_feature_names_out(),\n",
    "                model.named_steps[\"classifier\"].feature_importances_,\n",
    "            )\n",
    "            feature_importances_df = (\n",
    "                pd.DataFrame(feature_importances, columns=[\"feature\", \"importance\"])\n",
    "                .sort_values(\"importance\", ascending=False)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"feature_importance_\", suffix=\".csv\") as f:\n",
    "                feature_importances_df.to_csv(f.name, index=False)\n",
    "                mlflow.log_artifact(f.name)\n",
    "            \n",
    "            # SHAP values\n",
    "            X_test_sample = X_test.sample(n=5000, random_state=42)\n",
    "            X_test_sample_prep = preprocessor.transform(X_test_sample)\n",
    "            explainer = shap.TreeExplainer(\n",
    "                model=model.named_steps[\"classifier\"],\n",
    "                feature_names=preprocessor.get_feature_names_out(),\n",
    "            )\n",
    "            # Because we are working with a binary classifier, we only need the SHAP values for the positive class.\n",
    "            # E.g., if you change 1->0 the waterfall plot flips backwards only.\n",
    "            shap_values = explainer(X_test_sample_prep)[:, :, 1]\n",
    "            shap_interaction_values = explainer.shap_interaction_values(X_test_sample_prep)\n",
    "\n",
    "            # SHAP beeswarm plot\n",
    "            shap.plots.beeswarm(shap_values, show=False)\n",
    "            plt.tight_layout()\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"shap_beeswarm_\", suffix=\".png\") as f:\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # SHAP interaction values heatmap\n",
    "            fig, ax = plot_shap_interaction_values(shap_interaction_values, preprocessor.get_feature_names_out())\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"shap_interactions_\", suffix=\".png\") as f:\n",
    "                fig.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # SHAP bar plot\n",
    "            shap.plots.bar(shap_values, show=False)\n",
    "            plt.tight_layout()\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"shap_bar_\", suffix=\".png\") as f:\n",
    "                plt.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Correlation matrix\n",
    "            fig, ax = plot_correlation_matrix(data=preprocessor.transform(X_test), columns=preprocessor.get_feature_names_out())\n",
    "            with tempfile.NamedTemporaryFile(prefix=\"correlation_matrix_\", suffix=\".png\") as f:\n",
    "                fig.savefig(f.name)\n",
    "                plt.close()\n",
    "                mlflow.log_artifact(f.name)\n",
    "\n",
    "            # Bankroll over time\n",
    "            results = (\n",
    "                pd.concat(\n",
    "                    [\n",
    "                        payouts,\n",
    "                        pd.Series(y_pred.astype(bool)).rename(\"pred\"),\n",
    "                        pd.Series(y_proba[:, 1]).rename(\"proba_true\"),\n",
    "                        y_test.astype(bool).reset_index(drop=True).rename(\"actual\"),\n",
    "                    ],\n",
    "                    axis=1,\n",
    "                )\n",
    "                .set_index(\"発走日時\")\n",
    "                .sort_index()\n",
    "                .dropna()\n",
    "            )\n",
    "            b = results[\"odds\"] - 1\n",
    "            p = results[\"proba_true\"]\n",
    "            q = 1 - p\n",
    "            japanize_matplotlib.japanize()\n",
    "            for confidence in [0.5, 0.65, 0.8]:\n",
    "                fig, ax = plt.subplots(figsize=(15, 5))\n",
    "                for multiplier in [0.1, 0.2, 0.3]:\n",
    "                    results[f\"kelly_{multiplier}\"] = kelly_criterion(b, p, q).clip(lower=0) * multiplier\n",
    "                    bankroll = 10_000\n",
    "                    history = []\n",
    "                    for i, row in results.iterrows():\n",
    "                        # bet in 100 yen increments\n",
    "                        bet_amount = round(row[f\"kelly_{multiplier}\"] * bankroll / 100) * 100\n",
    "                        bet = bet_amount > 0 and row[\"proba_true\"] >= confidence\n",
    "                        if bet and row[\"actual\"] is True:\n",
    "                            bankroll += (row[\"odds\"] - 1) * bet_amount\n",
    "                        elif bet and row[\"actual\"] is False:\n",
    "                            bankroll -= bet_amount\n",
    "                        history.append(bankroll)\n",
    "                    results[\"bankroll\"] = history\n",
    "                    results[\"bankroll\"].plot(ax=ax, label=f\"Kelly Criterion x {multiplier}\")\n",
    "                ax.set_title(\"Bankroll over time (Confidence: {confidence})\")\n",
    "                ax.set_ylabel(\"Bankroll\")\n",
    "                ax.set_xlabel(\"Date\")\n",
    "                ax.legend()\n",
    "                plt.tight_layout()\n",
    "                plt.grid()\n",
    "                with tempfile.NamedTemporaryFile(prefix=f\"bets_{confidence}_confidence_\", suffix=\".png\") as f:\n",
    "                    fig.savefig(f.name)\n",
    "                    plt.close()\n",
    "                    mlflow.log_artifact(f.name)\n",
    "            return {\"status\": STATUS_OK, \"params\": params, \"model\": model, **metrics}\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "from hyperopt import Trials, fmin, hp, tpe, SparkTrials\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "space = {\n",
    "    \"smote__random_state\": random_state,\n",
    "    # \"features__decay_rate\": hp.uniform(\"decay_rate\", 0.001, 0.1),\n",
    "    \"classifier__boosting_type\": \"gbdt\",\n",
    "    \"classifier__learning_rate\": hp.loguniform(\"learning_rate\", -5, 0),  # between e^-5 and 1\n",
    "    \"classifier__n_estimators\": scope.int(hp.quniform(\"n_estimators\", 100, 1000, 1)),\n",
    "    \"classifier__max_depth\": scope.int(hp.quniform(\"max_depth\", 3, 10, 1)),\n",
    "    \"classifier__num_leaves\": scope.int(hp.quniform(\"num_leaves\", 20, 150, 1)),\n",
    "    \"classifier__min_child_samples\": scope.int(hp.quniform(\"min_child_samples\", 20, 500, 1)),\n",
    "    \"classifier__feature_fraction\": hp.uniform(\"feature_fraction\", 0.5, 1.0),\n",
    "    \"classifier__lambda_l1\": hp.uniform(\"lambda_l1\", 0, 5),\n",
    "    \"classifier__lambda_l2\": hp.uniform(\"lambda_l2\", 0, 5),\n",
    "    \"classifier__min_split_gain\": hp.uniform(\"min_split_gain\", 0, 1),\n",
    "    \"classifier__min_child_weight\": hp.uniform(\"min_child_weight\", 0.001, 10),\n",
    "    \"classifier__subsample\": hp.uniform(\"subsample\", 0.5, 1),\n",
    "    \"classifier__colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1),\n",
    "    \"classifier__reg_alpha\": hp.uniform(\"reg_alpha\", 0.0, 1.0),\n",
    "    \"classifier__reg_lambda\": hp.uniform(\"reg_lambda\", 0.0, 1.0),\n",
    "    \"classifier__objective\": \"binary\",\n",
    "    \"classifier__verbose\": -1,\n",
    "    \"classifier__random_state\": random_state,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "payouts = (\n",
    "    X_test[[\"meta_発走日時\", \"meta_複勝払戻金\", \"meta_複勝オッズ\"]]\n",
    "    .reset_index(drop=True)\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"meta_発走日時\": \"発走日時\",\n",
    "            \"meta_複勝払戻金\": \"payout\",\n",
    "            \"meta_複勝オッズ\": \"odds\",\n",
    "        }\n",
    "    )\n",
    "    .assign(発走日時=lambda x: pd.to_datetime(x[\"発走日時\"]))\n",
    ")\n",
    "\n",
    "experiment_name = \"20240316-eda1\"\n",
    "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "fn = create_objective_fn(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    payouts=payouts,\n",
    "    payout_column_name=\"payout\",\n",
    "    mlflow_experiment_name=experiment_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.002515 seconds\n",
      "TPE using 0 trials\n",
      "build_posterior_wrapper took 0.001690 seconds\n",
      "TPE using 1/1 trials with best loss inf\n",
      "build_posterior_wrapper took 0.001564 seconds\n",
      "TPE using 2/2 trials with best loss inf\n",
      "build_posterior_wrapper took 0.002073 seconds                       (0 + 1) / 1]\n",
      "TPE using 3/3 trials with best loss inf\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 2:>    (0 + 1) / 1]1]\n",
      "Setuptools is replacing distutils.\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:58<28:10, 58.29s/trial, best loss: -0.38905658569306695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001901 secondse 2:>                  (0 + 1) / 1]\n",
      "TPE using 4/4 trials with best loss -0.389057\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [01:00<11:45, 25.19s/trial, best loss: -0.38905658569306695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001604 seconds\n",
      "TPE using 5/5 trials with best loss -0.389057\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 4:>    (0 + 1) / 1]1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [01:20<10:17, 22.86s/trial, best loss: -0.38905658569306695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001671 secondse 4:>                  (0 + 1) / 1]\n",
      "TPE using 6/6 trials with best loss -0.389057\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 5:>    (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [02:24<16:59, 39.22s/trial, best loss: -0.38905658569306695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001632 secondse 5:>                  (0 + 1) / 1]\n",
      "TPE using 7/7 trials with best loss -0.389057\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 6:>    (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 4:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [03:14<17:59, 43.18s/trial, best loss: -0.3938738138838022] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001835 seconds\n",
      "TPE using 8/8 trials with best loss -0.393874\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [03:27<13:10, 32.95s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [03:28<08:37, 22.50s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001676 seconds\n",
      "TPE using 9/9 trials with best loss -0.393874\n",
      "build_posterior_wrapper took 0.002738 seconds                       (0 + 1) / 1]\n",
      "TPE using 10/10 trials with best loss -0.393874\n",
      "Setuptools is replacing distutils.) / 1][Stage 8:>                  (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 9:>    (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 7:>                  (0 + 1) / 1][Stage 9:>                  (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [04:30<12:46, 34.84s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001584 seconds\n",
      "TPE using 11/11 trials with best loss -0.393874\n",
      "Setuptools is replacing distutils.:>    (0 + 1) / 1][Stage 10:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [04:46<10:08, 28.97s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001737 secondse 10:>                 (0 + 1) / 1]\n",
      "TPE using 12/12 trials with best loss -0.393874\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [04:48<06:52, 20.65s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001677 secondse 11:>                 (0 + 1) / 1]\n",
      "TPE using 13/13 trials with best loss -0.393874\n",
      "Setuptools is replacing distutils.1:>   (0 + 1) / 1][Stage 12:>   (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [05:31<08:43, 27.54s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.005236 seconds\n",
      "TPE using 14/14 trials with best loss -0.393874\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [05:33<05:56, 19.78s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001631 secondse 13:>                 (0 + 1) / 1]\n",
      "TPE using 15/15 trials with best loss -0.393874\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [05:43<04:46, 16.83s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001933 secondse 14:>                 (0 + 1) / 1]\n",
      "TPE using 16/16 trials with best loss -0.393874\n",
      "Setuptools is replacing distutils.4:>   (0 + 1) / 1][Stage 15:>   (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [06:32<07:05, 26.62s/trial, best loss: -0.3938738138838022]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001613 secondse 14:>                 (0 + 1) / 1]\n",
      "TPE using 17/17 trials with best loss -0.393874\n",
      "Setuptools is replacing distutils.4:>   (0 + 1) / 1][Stage 16:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [06:57<06:32, 26.16s/trial, best loss: -0.3951001254978993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001659 secondse 16:>                 (0 + 1) / 1]\n",
      "TPE using 18/18 trials with best loss -0.395100\n",
      "Setuptools is replacing distutils.6:>   (0 + 1) / 1][Stage 17:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [07:15<05:32, 23.73s/trial, best loss: -0.3951001254978993]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001654 secondse 17:>                 (0 + 1) / 1]\n",
      "TPE using 19/19 trials with best loss -0.395100\n",
      "Setuptools is replacing distutils.7:>   (0 + 1) / 1][Stage 18:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [08:49<09:40, 44.68s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001701 secondse 18:>                 (0 + 1) / 1]\n",
      "TPE using 20/20 trials with best loss -0.396149\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [08:53<06:29, 32.46s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001649 secondse 19:>                 (0 + 1) / 1]\n",
      "TPE using 21/21 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.9:>   (0 + 1) / 1][Stage 20:>   (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [09:38<06:39, 36.29s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001621 secondse 19:>                 (0 + 1) / 1]\n",
      "TPE using 22/22 trials with best loss -0.396149\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 19:>                 (0 + 1) / 1][Stage 21:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [09:44<04:32, 27.21s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001717 seconds\n",
      "TPE using 23/23 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.1:>   (0 + 1) / 1][Stage 22:>   (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [10:43<05:31, 36.83s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001689 secondse 21:>                 (0 + 1) / 1]\n",
      "TPE using 24/24 trials with best loss -0.396149\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [10:45<03:31, 26.38s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001654 seconds                       (0 + 1) / 1]\n",
      "TPE using 25/25 trials with best loss -0.396149\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [10:48<02:15, 19.38s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001722 secondse 24:>                 (0 + 1) / 1]\n",
      "TPE using 26/26 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.4:>   (0 + 1) / 1][Stage 25:>   (0 + 1) / 1]\n",
      "Setuptools is replacing distutils.\n",
      "Setuptools is replacing distutils.\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 24:>                 (0 + 1) / 1][Stage 25:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [12:21<04:07, 41.28s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001652 seconds\n",
      "TPE using 27/27 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.5:>   (0 + 1) / 1][Stage 26:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 24:>                 (0 + 1) / 1][Stage 25:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [13:01<03:24, 40.95s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001626 seconds\n",
      "TPE using 28/28 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.5:>   (0 + 1) / 1][Stage 27:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 25:>                 (0 + 1) / 1][Stage 27:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [14:28<03:39, 54.89s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_posterior_wrapper took 0.001751 seconds\n",
      "TPE using 29/29 trials with best loss -0.396149\n",
      "Setuptools is replacing distutils.7:>   (0 + 1) / 1][Stage 28:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n",
      "[Stage 25:>                 (0 + 1) / 1][Stage 28:>                 (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [15:01<02:24, 48.07s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setuptools is replacing distutils.8:>   (0 + 1) / 1][Stage 29:>   (0 + 1) / 1]\n",
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [15:56<01:40, 50.22s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [16:21<00:42, 42.68s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing down clientserver connection                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [17:01<00:00, 34.05s/trial, best loss: -0.39614876536937305]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Queue empty, exiting run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Closing down clientserver connection\n",
      "Total Trials: 30: 30 succeeded, 0 failed, 0 cancelled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.9714517337924691,\n",
       " 'feature_fraction': 0.9895358123133442,\n",
       " 'lambda_l1': 1.2789820470995301,\n",
       " 'lambda_l2': 2.8427382476927328,\n",
       " 'learning_rate': 0.031200627683390197,\n",
       " 'max_depth': 8.0,\n",
       " 'min_child_samples': 185.0,\n",
       " 'min_child_weight': 6.3447195744828955,\n",
       " 'min_split_gain': 0.618233497310962,\n",
       " 'n_estimators': 345.0,\n",
       " 'num_leaves': 67.0,\n",
       " 'reg_alpha': 0.6743049381465438,\n",
       " 'reg_lambda': 0.6569291767377803,\n",
       " 'subsample': 0.5329008714579213}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/16 19:23:15 WARN TransportChannelHandler: Exception in connection from /192.168.40.105:57621\n",
      "java.io.IOException: Operation timed out\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)\n",
      "\tat java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:47)\n",
      "\tat java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:339)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:293)\n",
      "\tat java.base/sun.nio.ch.IOUtil.read(IOUtil.java:268)\n",
      "\tat java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:425)\n",
      "\tat io.netty.buffer.PooledByteBuf.setBytes(PooledByteBuf.java:254)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1132)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:357)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:151)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:788)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1589)\n"
     ]
    }
   ],
   "source": [
    "# early_stop_fn = no_progress_loss(iteration_stop_count=10, absolute_increase=0.001)\n",
    "# trials = Trials()\n",
    "# fmin(\n",
    "#     fn=fn,\n",
    "#     space=space,\n",
    "#     algo=tpe.suggest,\n",
    "#     max_evals=1,\n",
    "#     trials=trials,\n",
    "# )\n",
    "\n",
    "trials = SparkTrials(parallelism=3, spark_session=spark)\n",
    "fmin(fn=fn, space=space, algo=tpe.suggest, max_evals=30, trials=trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
